<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MIG Support in Kubernetes &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/mig-k8s.html"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="NVIDIA GPUs with Google Cloud’s Anthos" href="anthos-guide.html" />
    <link rel="prev" title="Install Kubernetes" href="install-k8s.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../contents.html">
            <img src="../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/about.html">About the Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/getting-started.html#install-nvidia-gpu-operator">Install NVIDIA GPU Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/advanced-configurations.html">Advanced Configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/contents.html">GPU Operator on OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/license.html">Licenses and Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install-k8s.html">Install Kubernetes</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MIG Support in Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#mig-strategies">MIG Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-mig-strategies-in-kubernetes">Using MIG Strategies in Kubernetes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#testing-with-different-strategies">Testing with Different Strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mig/mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mig/mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../contents.html" class="icon icon-home"></a> &raquo;</li>
      <li>MIG Support in Kubernetes</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mig-support-in-kubernetes">
<span id="mig-k8s"></span><h1>MIG Support in Kubernetes<a class="headerlink" href="#mig-support-in-kubernetes" title="Permalink to this heading"></a></h1>
<p>The new Multi-Instance GPU (MIG) feature allows the NVIDIA A100 GPU to be securely partitioned into up to
seven separate GPU Instances for CUDA applications, providing multiple users with separate GPU resources for
optimal GPU utilization. This feature is particularly beneficial for workloads that do not fully saturate the GPU’s
compute capacity and therefore users may want to run different workloads in parallel to maximize utilization.</p>
<p>This document provides an overview of the necessary software to enable MIG support for Kubernetes.
Refer to the <a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">MIG User Guide</a> for more details on the technical concepts,
setting up MIG and the NVIDIA Container Toolkit for running containers with MIG.</p>
<p>The deployment workflow requires these pre-requisites:</p>
<ol class="arabic simple">
<li><p>You have installed the NVIDIA R450+ datacenter (450.80.02+) drivers required for NVIDIA A100.</p></li>
<li><p>You have installed the NVIDIA Container Toolkit v2.5.0+</p></li>
<li><p>You already have a Kubernetes deployment up and running with access to at least one NVIDIA A100 GPU.</p></li>
</ol>
<p>Once these prerequisites have been met, you can proceed to deploy a MIG capable version of the NVIDIA <code class="docutils literal notranslate"><span class="pre">k8s-device-plugin</span></code> and (optionally)
the <code class="docutils literal notranslate"><span class="pre">gpu-feature-discovery</span></code> component in your cluster, so that Kubernetes can schedule pods on the available MIG devices.</p>
<p>The minimum versions of the software components required are enumerated below:</p>
<ol class="arabic simple">
<li><p>NVIDIA R450+ datacenter driver: 450.80.02+</p></li>
<li><p>NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>): v2.5.0+</p></li>
<li><p>NVIDIA <a class="reference external" href="https://github.com/NVIDIA/k8s-device-plugin/tree/v0.7.0">k8s-device-plugin</a>: v0.7.0+</p></li>
<li><p>NVIDIA <a class="reference external" href="https://github.com/NVIDIA/gpu-feature-discovery/tree/v0.2.0">gpu-feature-discovery</a>: v0.2.0+</p></li>
</ol>
<section id="mig-strategies">
<h2>MIG Strategies<a class="headerlink" href="#mig-strategies" title="Permalink to this heading"></a></h2>
<p>NVIDIA provides two strategies for exposing MIG devices on a Kubernetes node.
For more details on the strategies, refer to the
<a class="reference external" href="https://docs.google.com/document/d/1mdgMQ8g7WmaI_XVVRrCvHPFPOMCm5LQD5JefgAh6N8g/edit">design document</a>.</p>
</section>
<section id="using-mig-strategies-in-kubernetes">
<h2>Using MIG Strategies in Kubernetes<a class="headerlink" href="#using-mig-strategies-in-kubernetes" title="Permalink to this heading"></a></h2>
<p>This section walks through the steps necessary to deploy and run the <code class="docutils literal notranslate"><span class="pre">k8s-device-plugin</span></code>
and <code class="docutils literal notranslate"><span class="pre">gpu-feature-discovery</span></code> components for the various MIG strategies. The preferred
approach for deployment is through Helm.</p>
<p>For alternate deployment methods, refer to the instructions
<a class="reference external" href="https://github.com/NVIDIA/k8s-device-plugin/tree/v0.7.0/#deployment-via-helm">here</a> and
<a class="reference external" href="https://github.com/NVIDIA/gpu-feature-discovery/tree/v0.2.0#deploying-via-helm-install-with-a-direct-url-to-the-helm-package">here</a>.</p>
<p>First, add the <code class="docutils literal notranslate"><span class="pre">nvidia-device-plugin</span></code> and <code class="docutils literal notranslate"><span class="pre">gpu-feature-discovery</span></code> helm repositories:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvdp<span class="w"> </span>https://nvidia.github.io/k8s-device-plugin
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvgfd<span class="w"> </span>https://nvidia.github.io/gpu-feature-discovery
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
<p>Then, verify that the <strong>v0.7.0</strong> version of the <em>nvidia-device-plugin</em> and the <strong>v0.2.0</strong> version
of <em>gpu-feature-discovery</em> is available:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>search<span class="w"> </span>repo<span class="w"> </span>nvdp<span class="w"> </span>--devel
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                           CHART VERSION  APP VERSION    DESCRIPTION</span>
<span class="go">nvdp/nvidia-device-plugin      0.7.0          0.7.0         A Helm chart for ...</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>search<span class="w"> </span>repo<span class="w"> </span>nvgfd<span class="w"> </span>--devel
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                           CHART VERSION  APP VERSION    DESCRIPTION</span>
<span class="go">nvgfd/gpu-feature-discovery  0.2.0          0.2.0           A Helm chart for ...</span>
</pre></div>
</div>
<p>Finally, select a MIG strategy and deploy the <em>nvidia-device-plugin</em> and <em>gpu-feature-discovery</em> components:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">MIG_STRATEGY</span><span class="o">=</span>&lt;none<span class="w"> </span><span class="p">|</span><span class="w"> </span>single<span class="w"> </span><span class="p">|</span><span class="w"> </span>mixed&gt;
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--version<span class="o">=</span><span class="m">0</span>.7.0<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--set<span class="w"> </span><span class="nv">migStrategy</span><span class="o">=</span><span class="si">${</span><span class="nv">MIG_STRATEGY</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>nvdp/nvidia-device-plugin
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--version<span class="o">=</span><span class="m">0</span>.2.0<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--set<span class="w"> </span><span class="nv">migStrategy</span><span class="o">=</span><span class="si">${</span><span class="nv">MIG_STRATEGY</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>nvgfd/gpu-feature-discovery
</pre></div>
</div>
</section>
<section id="testing-with-different-strategies">
<h2>Testing with Different Strategies<a class="headerlink" href="#testing-with-different-strategies" title="Permalink to this heading"></a></h2>
<p>This section walks through the steps necessary to test each of the MIG strategies.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With a default setup, only <strong>one</strong> device type can be requested by a container at a time for
the <cite>mixed</cite> strategy. If more than one device type is requested by the container, then the
device received is undefined. For example, a container cannot request both <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code>
and <code class="docutils literal notranslate"><span class="pre">nvidia.com/mig-3g.20gb</span></code> at the same time. However, it can request multiple instances
of the same resource type (e.g. <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu:</span> <span class="pre">2</span></code> or <code class="docutils literal notranslate"><span class="pre">nvidia.com/mig-3g.20gb:</span> <span class="pre">2</span></code>) without restriction.</p>
<p>To mitigate this behavior, we recommend following the guidance outlined in the <a class="reference external" href="https://docs.google.com/document/d/1zy0key-EL6JH50MZgwg96RPYxxXXnVUdxLZwGiyqLd8">document</a>.</p>
</div>
<section id="the-none-strategy">
<h3>The <code class="docutils literal notranslate"><span class="pre">none</span></code> strategy<a class="headerlink" href="#the-none-strategy" title="Permalink to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">none</span></code> strategy is designed to keep the <em>nvidia-device-plugin</em> running the same as it always
has. The plugin will make no distinction between GPUs that have either MIG enabled or not, and
will enumerate all GPUs on the node, making them available using the <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code> resource type.</p>
<section id="testing">
<h4>Testing<a class="headerlink" href="#testing" title="Permalink to this heading"></a></h4>
<p>To test this strategy we check the enumeration of a GPU with and without MIG enabled and make
sure we can see it in both cases. The test assumes a single GPU on a single node in the cluster.</p>
<ol class="arabic">
<li><p>Verify that MIG is disabled on the GPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  A100-SXM4-40GB      Off  | 00000000:36:00.0 Off |                    0 |</span>
<span class="go">| N/A   29C    P0    62W / 400W |      0MiB / 40537MiB |      6%      Default |</span>
<span class="go">|                               |                      |             Disabled |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>
</pre></div>
</div>
</li>
<li><p>Start the <em>nvidia-device-plugin</em> with the <code class="docutils literal notranslate"><span class="pre">none</span></code> strategy as described in the previous section.
Restart the plugin if its already running.</p></li>
<li><p>Observe that 1 GPU is available on the node with resource type <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>describe<span class="w"> </span>node
<span class="go">...</span>
<span class="go">Capacity:</span>
<span class="go">nvidia.com/gpu:          1</span>
<span class="go">...</span>
<span class="go">Allocatable:</span>
<span class="go">nvidia.com/gpu:          1</span>
<span class="go">...</span>
</pre></div>
</div>
</li>
<li><p>Start <em>gpu-feature-discovery</em> with the <code class="docutils literal notranslate"><span class="pre">none</span></code> strategy as described in the previous section
Restart the plugin if its already running.</p></li>
<li><p>Observe that the proper set of labels have been applied for this MIG strategy:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>jq<span class="w"> </span><span class="s1">&#39;.items[0].metadata.labels | with_entries(select(.key | startswith(&quot;nvidia.com&quot;)))&#39;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;450&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;80&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;02&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1605312111&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;ampere&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;NVIDIA DGX&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;40537&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB&quot;</span>
<span class="go">}</span>
</pre></div>
</div>
</li>
<li><p>Deploy a pod to consume the GPU and run <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--rm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--image<span class="o">=</span>nvidia/cuda:11.0-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--restart<span class="o">=</span>Never<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--limits<span class="o">=</span>nvidia.com/gpu<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>mig-none-example<span class="w"> </span>--<span class="w"> </span>nvidia-smi<span class="w"> </span>-L
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-15f0798d-c807-231d-6525-a7827081f0f1)</span>
</pre></div>
</div>
</li>
<li><p>Enable MIG on the GPU (requires stopping all GPU clients first)</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>stop<span class="w"> </span>kubelet
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>nvidia-smi<span class="w"> </span>-mig<span class="w"> </span><span class="m">1</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Enabled MIG Mode for GPU 00000000:36:00.0</span>
<span class="go">All done.</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi<span class="w"> </span>--query-gpu<span class="o">=</span>mig.mode.current<span class="w"> </span>--format<span class="o">=</span>csv,noheader
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Enabled</span>
</pre></div>
</div>
</li>
<li><p>Restart the <code class="docutils literal notranslate"><span class="pre">kubelet</span></code> and the plugins</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>start<span class="w"> </span>kubelet
</pre></div>
</div>
</li>
<li><p>Observe that 1 GPU is available on the node with resource type <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>describe<span class="w"> </span>node
<span class="go">...</span>
<span class="go">Capacity:</span>
<span class="go">nvidia.com/gpu:          1</span>
<span class="go">...</span>
<span class="go">Allocatable:</span>
<span class="go">nvidia.com/gpu:          1</span>
<span class="go">...</span>
</pre></div>
</div>
</li>
<li><p>Observe that the labels haven’t changed</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>jq<span class="w"> </span><span class="s1">&#39;.items[0].metadata.labels | with_entries(select(.key | startswith(&quot;nvidia.com&quot;)))&#39;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;450&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;80&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;02&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1605312111&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;ampere&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;NVIDIA DGX&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;40537&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB&quot;</span>
<span class="go">}</span>
</pre></div>
</div>
</li>
<li><p>Deploy a pod to consume the GPU and run nvidia-smi</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--rm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--image<span class="o">=</span>nvidia/cuda:9.0-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--restart<span class="o">=</span>Never<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--limits<span class="o">=</span>nvidia.com/gpu<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>mig-none-example<span class="w"> </span>--<span class="w"> </span>nvidia-smi<span class="w"> </span>-L
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-15f0798d-c807-231d-6525-a7827081f0f1)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
<section id="the-single-strategy">
<h3>The <code class="docutils literal notranslate"><span class="pre">single</span></code> strategy<a class="headerlink" href="#the-single-strategy" title="Permalink to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">single</span></code> strategy is designed to keep the user-experience of working with GPUs in Kubernetes the
same as it has always been. MIG devices are enumerated with the nvidia.com/gpu resource type just as before.
However, the properties associated with that resource type now map to the MIG devices available on that node,
instead of the full GPUs.</p>
<section id="id2">
<h4>Testing<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h4>
<p>To test this strategy, we check that MIG devices of a single type are enumerated using the traditional <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code>
resource type. The test assumes a single GPU on a single node in the cluster with MIG enabled on it already.</p>
<ol class="arabic">
<li><p>Verify that MIG is enabled on the GPU and no MIG devices present:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  A100-SXM4-40GB      On   | 00000000:00:04.0 Off |                   On |</span>
<span class="go">| N/A   32C    P0    43W / 400W |      0MiB / 40537MiB |     N/A      Default |</span>
<span class="go">|                               |                      |              Enabled |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| MIG devices:                                                                |</span>
<span class="go">+------------------+----------------------+-----------+-----------------------+</span>
<span class="go">| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |</span>
<span class="go">|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|</span>
<span class="go">|                  |                      |        ECC|                       |</span>
<span class="go">|==================+======================+===========+=======================|</span>
<span class="go">|  No MIG devices found                                                       |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| Processes:                                                                  |</span>
<span class="go">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="go">|        ID   ID                                                   Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|  No running processes found                                                 |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
</li>
<li><p>Create 7 single-slice MIG devices on the GPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>nvidia-smi<span class="w"> </span>mig<span class="w"> </span>-cgi<span class="w"> </span><span class="m">19</span>,19,19,19,19,19,19<span class="w"> </span>-C
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi<span class="w"> </span>-L
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-4200ccc0-2667-d4cb-9137-f932c716232a)</span>
<span class="go">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/7/0)</span>
<span class="go">  MIG 1g.5gb Device 1: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/8/0)</span>
<span class="go">  MIG 1g.5gb Device 2: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/9/0)</span>
<span class="go">  MIG 1g.5gb Device 3: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/10/0)</span>
<span class="go">  MIG 1g.5gb Device 4: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/11/0)</span>
<span class="go">  MIG 1g.5gb Device 5: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/12/0)</span>
<span class="go">  MIG 1g.5gb Device 6: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/13/0)</span>
</pre></div>
</div>
</li>
<li><p>Start the <em>nvidia-device-plugin</em> plugin with the <code class="docutils literal notranslate"><span class="pre">single</span></code> strategy as described in the previous section. If its already
running, then restart the plugin.</p></li>
<li><p>Observe that 7 MIG devices are available on the node with resource type <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>describe<span class="w"> </span>node
<span class="go">...</span>
<span class="go">Capacity:</span>
<span class="go">nvidia.com/gpu:          7</span>
<span class="go">...</span>
<span class="go">Allocatable:</span>
<span class="go">nvidia.com/gpu:          7</span>
<span class="go">...</span>
</pre></div>
</div>
</li>
<li><p>Start <em>gpu-feature-discovery</em> with the <code class="docutils literal notranslate"><span class="pre">single</span></code> strategy as described in the previous section. If its already running, then
restart the plugin.</p></li>
<li><p>Observe that the proper set of labels have been applied for this MIG strategy:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>jq<span class="w"> </span><span class="s1">&#39;.items[0].metadata.labels | with_entries(select(.key | startswith(&quot;nvidia.com&quot;)))&#39;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;450&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;80&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;02&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1605657366&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;7&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.copy&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.decoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.encoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.jpeg&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.ofa&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;ampere&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;NVIDIA DGX&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;4864&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.multiprocessors&quot;: &quot;14&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB-MIG-1g.5gb&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.slices.ci&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.slices.gi&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig.strategy&quot;: &quot;single&quot;</span>
<span class="go">}</span>
</pre></div>
</div>
</li>
<li><p>Deploy 7 pods, each consuming one MIG device (then read their logs and delete them)</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="k">for</span><span class="w"> </span>i<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span>seq<span class="w"> </span><span class="m">7</span><span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="go">   kubectl run \</span>
<span class="go">      --image=nvidia/cuda:11.0-base \</span>
<span class="go">      --restart=Never \</span>
<span class="go">      --limits=nvidia.com/gpu=1 \</span>
<span class="go">      mig-single-example-${i} -- bash -c &quot;nvidia-smi -L; sleep infinity&quot;</span>
<span class="go">done</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pod/mig-single-example-1 created</span>
<span class="go">pod/mig-single-example-2 created</span>
<span class="go">pod/mig-single-example-3 created</span>
<span class="go">pod/mig-single-example-4 created</span>
<span class="go">pod/mig-single-example-5 created</span>
<span class="go">pod/mig-single-example-6 created</span>
<span class="go">pod/mig-single-example-7 created</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="k">for</span><span class="w"> </span>i<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span>seq<span class="w"> </span><span class="m">7</span><span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="go">echo &quot;mig-single-example-${i}&quot;;</span>
<span class="go">kubectl logs mig-single-example-${i}</span>
<span class="go">echo &quot;&quot;;</span>
<span class="go">done</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">mig-single-example-1</span>
<span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-4200ccc0-2667-d4cb-9137-f932c716232a)</span>
<span class="go">   MIG 1g.5gb Device 0: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/7/0)</span>

<span class="go">mig-single-example-2</span>
<span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-4200ccc0-2667-d4cb-9137-f932c716232a)</span>
<span class="go">   MIG 1g.5gb Device 0: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/9/0)</span>

<span class="go">...</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="k">for</span><span class="w"> </span>i<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span>seq<span class="w"> </span><span class="m">7</span><span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="go">kubectl delete pod mig-single-example-${i};</span>
<span class="go">done</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pod &quot;mig-single-example-1&quot; deleted</span>
<span class="go">pod &quot;mig-single-example-2&quot; deleted</span>
<span class="go">...</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
<section id="the-mixed-strategy">
<h3>The <code class="docutils literal notranslate"><span class="pre">mixed</span></code> strategy<a class="headerlink" href="#the-mixed-strategy" title="Permalink to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">mixed</span></code> strategy is designed to enumerate a different resource type for every MIG device
configuration available in the cluster.</p>
<section id="id3">
<h4>Testing<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h4>
<p>To test this strategy, we check that all MIG devices are enumerated using their fully qualified name
of the form <code class="docutils literal notranslate"><span class="pre">nvidia.com/mig-&lt;slice_count&gt;g.&lt;memory_size&gt;gb</span></code>. The test assumes a single GPU on a single
node in the cluster with MIG enabled on it already.</p>
<ol class="arabic">
<li><p>Verify that MIG is enabled on the GPU and no MIG devices present:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  A100-SXM4-40GB      On   | 00000000:00:04.0 Off |                   On |</span>
<span class="go">| N/A   32C    P0    43W / 400W |      0MiB / 40537MiB |     N/A      Default |</span>
<span class="go">|                               |                      |              Enabled |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| MIG devices:                                                                |</span>
<span class="go">+------------------+----------------------+-----------+-----------------------+</span>
<span class="go">| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |</span>
<span class="go">|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|</span>
<span class="go">|                  |                      |        ECC|                       |</span>
<span class="go">|==================+======================+===========+=======================|</span>
<span class="go">|  No MIG devices found                                                       |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| Processes:                                                                  |</span>
<span class="go">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="go">|        ID   ID                                                   Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|  No running processes found                                                 |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
</li>
<li><p>Create 3 different MIG devices of different sizes on the GPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>nvidia-smi<span class="w"> </span>mig<span class="w"> </span>-cgi<span class="w"> </span><span class="m">9</span>,14,19<span class="w"> </span>-C
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi<span class="w"> </span>-L
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-4200ccc0-2667-d4cb-9137-f932c716232a)</span>
<span class="go">  MIG 3g.20gb Device 0: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/2/0)</span>
<span class="go">  MIG 2g.10gb Device 1: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/3/0)</span>
<span class="go">  MIG 1g.5gb Device 2: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/9/0)</span>
</pre></div>
</div>
</li>
<li><p>Start the <em>nvidia-device-plugin</em> plugin with the <code class="docutils literal notranslate"><span class="pre">mixed</span></code> strategy as described in the previous section. If its already
running, then restart the plugin.</p></li>
<li><p>Observe that 3 MIG devices are available on the node with resource type <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>describe<span class="w"> </span>node
<span class="go">...</span>
<span class="go">Capacity:</span>
<span class="go">nvidia.com/mig-1g.5gb:   1</span>
<span class="go">nvidia.com/mig-2g.10gb:  1</span>
<span class="go">nvidia.com/mig-3g.20gb:  1</span>
<span class="go">...</span>
<span class="go">Allocatable:</span>
<span class="go">nvidia.com/mig-1g.5gb:   1</span>
<span class="go">nvidia.com/mig-2g.10gb:  1</span>
<span class="go">nvidia.com/mig-3g.20gb:  1</span>
<span class="go">...</span>
</pre></div>
</div>
</li>
<li><p>Start <em>gpu-feature-discovery</em> with the <code class="docutils literal notranslate"><span class="pre">mixed</span></code> strategy as described in the previous section. If its already running, then
restart the plugin.</p></li>
<li><p>Observe that the proper set of labels have been applied for this MIG strategy:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>jq<span class="w"> </span><span class="s1">&#39;.items[0].metadata.labels | with_entries(select(.key | startswith(&quot;nvidia.com&quot;)))&#39;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;450&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;80&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;02&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1605658841&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;ampere&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;NVIDIA DGX&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;40537&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.engines.copy&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.engines.decoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.engines.encoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.engines.jpeg&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.engines.ofa&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.memory&quot;: &quot;4864&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.multiprocessors&quot;: &quot;14&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.slices.ci&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-1g.5gb.slices.gi&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.engines.copy&quot;: &quot;2&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.engines.decoder&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.engines.encoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.engines.jpeg&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.engines.ofa&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.memory&quot;: &quot;9984&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.multiprocessors&quot;: &quot;28&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.slices.ci&quot;: &quot;2&quot;,</span>
<span class="go">&quot;nvidia.com/mig-2g.10gb.slices.gi&quot;: &quot;2&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.engines.copy&quot;: &quot;3&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.engines.decoder&quot;: &quot;2&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.engines.encoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.engines.jpeg&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.engines.ofa&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.memory&quot;: &quot;20096&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.multiprocessors&quot;: &quot;42&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.slices.ci&quot;: &quot;3&quot;,</span>
<span class="go">&quot;nvidia.com/mig-3g.21gb.slices.gi&quot;: &quot;3&quot;,</span>
<span class="go">&quot;nvidia.com/mig.strategy&quot;: &quot;mixed&quot;</span>
<span class="go">}</span>
</pre></div>
</div>
</li>
<li><p>Deploy 3 pods, each consuming one of the available MIG devices</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--rm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--image<span class="o">=</span>nvidia/cuda:11.0-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--restart<span class="o">=</span>Never<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--limits<span class="o">=</span>nvidia.com/mig-1g.5gb<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>mig-mixed-example<span class="w"> </span>--<span class="w"> </span>nvidia-smi<span class="w"> </span>-L
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-4200ccc0-2667-d4cb-9137-f932c716232a)</span>
<span class="go">MIG 1g.5gb Device 0: (UUID: MIG-GPU-4200ccc0-2667-d4cb-9137-f932c716232a/9/0)</span>
<span class="go">pod &quot;mig-mixed-example&quot; deleted</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install-k8s.html" class="btn btn-neutral float-left" title="Install Kubernetes" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="anthos-guide.html" class="btn btn-neutral float-right" title="NVIDIA GPUs with Google Cloud’s Anthos" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-03-13.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>