<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Getting Started &mdash; NVIDIA GPU Operator 23.9.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="_static/api-styles.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/mermaid-init.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/design-tabs.js"></script>
        <script crossorigin="anonymous" integrity="sha256-QdTG1YTLLTwD3b95jLqFxpQX9uYuJMNAtVZgwKX4oYU=" src="https://cdn.jsdelivr.net/npm/mermaid@9.3.0/dist/mermaid.min.js"></script>
        <script src="_static/mermaid-init.js"></script>
        <script src="_static/version.js"></script>
        <script src="_static/social-media.js"></script>
        <script>initMermaid();</script>
    <script src="_static/js/theme.js"></script>
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Platform Support" href="platform-support.html" />
    <link rel="prev" title="About the NVIDIA GPU Operator" href="overview.html" />
 


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >


<a href="index.html">
  <img src="_static/nvidia-logo-white.png" class="logo" alt="Logo"/>
</a>

<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">About the Operator</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-driver-configuration.html">GPU Driver CRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced configurations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-proxy.html">Install GPU Operator in Proxy Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-air-gapped.html">Install NVIDIA GPU Operator in Air-Gapped Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-outdated-kernels.html">Considerations when Installing with Outdated Kernels in Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom-driver-params.html">Customizing NVIDIA GPU Driver Parameters during Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="precompiled-drivers.html">Precompiled Driver Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="cdi.html">Container Device Interface Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-kata.html">GPU Operator with Kata Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-confidential-containers.html">GPU Operator with Confidential Containers and Kata</a></li>
<li class="toctree-l1"><a class="reference internal" href="amazon-eks.html">GPU Operator with Amazon EKS</a></li>
<li class="toctree-l1"><a class="reference internal" href="microsoft-aks.html">GPU Operator with Azure AKS</a></li>
<li class="toctree-l1"><a class="reference internal" href="google-gke.html">GPU Operator with Google GKE</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NVIDIA GPU Operator</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
<li>
    <a href="https://docs.nvidia.com">NVIDIA Docs Hub</a>
    <i class="fa fa-chevron-right" aria-hidden="true"></i>
</li>
<li>
    <a href="https://docs.nvidia.com/datacenter/cloud-native/">NVIDIA Cloud Native Technologies</a>
    <i class="fa fa-chevron-right" aria-hidden="true"></i>
</li>
<li>Getting Started</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="getting-started">
<span id="operator-install-guide"></span><h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline"></a></h1>
<p>This document provides instructions, including pre-requisites for getting started with the NVIDIA GPU Operator.</p>
<hr class="docutils" />
<section id="red-hat-openshift-4">
<h2>Red Hat OpenShift 4<a class="headerlink" href="#red-hat-openshift-4" title="Permalink to this headline"></a></h2>
<p>For installing the GPU Operator on clusters with Red Hat OpenShift using RHCOS worker nodes,
follow the <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/introduction.html#openshift-introduction" title="(in NVIDIA GPU Operator on Red Hat OpenShift Container Platform)"><span class="xref std std-ref">user guide</span></a>.</p>
</section>
<hr class="docutils" />
<section id="vmware-vsphere-with-tanzu">
<h2>VMware vSphere with Tanzu<a class="headerlink" href="#vmware-vsphere-with-tanzu" title="Permalink to this headline"></a></h2>
<p>For installing the GPU Operator on VMware vSphere with Tanzu leveraging NVIDIA AI Enterprise,
follow the <a class="reference internal" href="install-gpu-operator-nvaie.html#install-gpu-operator-nvaie"><span class="std std-ref">NVIDIA AI Enterprise document</span></a>.</p>
</section>
<hr class="docutils" />
<section id="google-cloud-anthos">
<h2>Google Cloud Anthos<a class="headerlink" href="#google-cloud-anthos" title="Permalink to this headline"></a></h2>
<p>For getting started with NVIDIA GPUs for Google Cloud Anthos, follow the getting started
<a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/anthos-guide.html">document</a>.</p>
</section>
<hr class="docutils" />
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline"></a></h2>
<p>Before installing the GPU Operator, you should ensure that the Kubernetes cluster meets some prerequisites.</p>
<ol class="arabic">
<li><p>All worker nodes in the Kubernetes cluster must run the same operating system version to use the NVIDIA GPU Driver container.
Alternatively, if you pre-install the NVIDIA GPU Driver on the nodes, then you can run different operating systems.</p></li>
<li><p>Nodes must be configured with a container engine such as Docker CE/EE, <code class="docutils literal notranslate"><span class="pre">cri-o</span></code>, or <code class="docutils literal notranslate"><span class="pre">containerd</span></code>. For <strong>docker</strong>, follow the official install
<a class="reference external" href="https://docs.docker.com/engine/install/">instructions</a>.</p></li>
<li><p>If your cluster uses Pod Security Admission (PSA) to restrict the behavior of pods,
label the namespace for the Operator to set the enforcement policy to privileged:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create ns gpu-operator
<span class="gp">$ </span>kubectl label --overwrite ns gpu-operator pod-security.kubernetes.io/enforce<span class="o">=</span>privileged
</pre></div>
</div>
</li>
<li><p>Node Feature Discovery (NFD) is a dependency for the Operator on each node.
By default, NFD master and worker are automatically deployed by the Operator.
If NFD is already running in the cluster, then you must disable deploying NFD when you install the Operator.</p>
<p>One way to determine if NFD is already running in the cluster is to check for a NFD label on your nodes:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get nodes -o json <span class="p">|</span> jq <span class="s1">&#39;.items[].metadata.labels | keys | any(startswith(&quot;feature.node.kubernetes.io&quot;))&#39;</span>
</pre></div>
</div>
<p>If the command output is <code class="docutils literal notranslate"><span class="pre">true</span></code>, then NFD is already running in the cluster.</p>
</li>
<li><p>For monitoring in Kubernetes 1.13 and 1.14, enable the kubelet <code class="docutils literal notranslate"><span class="pre">KubeletPodResources</span></code> <a class="reference external" href="https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/">feature</a>
gate. From Kubernetes 1.15 onwards, its enabled by default.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To enable the <code class="docutils literal notranslate"><span class="pre">KubeletPodResources</span></code> feature gate, run the following command: <code class="docutils literal notranslate"><span class="pre">echo</span> <span class="pre">-e</span> <span class="pre">&quot;KUBELET_EXTRA_ARGS=--feature-gates=KubeletPodResources=true&quot;</span> <span class="pre">|</span> <span class="pre">sudo</span> <span class="pre">tee</span> <span class="pre">/etc/default/kubelet</span></code></p>
</div>
<p>Before installing the GPU Operator on NVIDIA vGPU, ensure the following.</p>
<ol class="arabic simple">
<li><p>The NVIDIA vGPU Host Driver version 12.0 (or later) is pre-installed on all hypervisors hosting NVIDIA vGPU accelerated Kubernetes worker node virtual machines. Please refer to <a class="reference external" href="https://docs.nvidia.com/grid/12.0/index.html">NVIDIA vGPU Documentation</a> for details.</p></li>
<li><p>A NVIDIA vGPU License Server is installed and reachable from all Kubernetes worker node virtual machines.</p></li>
<li><p>A private registry is available to upload the NVIDIA vGPU specific driver container image.</p></li>
<li><p>Each Kubernetes worker node in the cluster has access to the private registry. Private registry access is usually managed through imagePullSecrets. See the Kubernetes Documentation for more information. The user is required to provide these secrets to the NVIDIA GPU-Operator in the driver section of the values.yaml file.</p></li>
<li><p>Git and Docker/Podman are required to build the vGPU driver image from source repository and push to local registry.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Uploading the NVIDIA vGPU driver to a publicly available repository or otherwise publicly sharing the driver is a violation of the NVIDIA vGPU EULA.</p>
</div>
<p>The rest of this document includes instructions for installing the GPU Operator on supported Linux distributions.</p>
</section>
<section id="install-nvidia-gpu-operator">
<span id="install-gpu-operator"></span><h2>Install NVIDIA GPU Operator<a class="headerlink" href="#install-nvidia-gpu-operator" title="Permalink to this headline"></a></h2>
<section id="install-helm">
<h3>Install Helm<a class="headerlink" href="#install-helm" title="Permalink to this headline"></a></h3>
<p>The preferred method to deploy the GPU Operator is using <code class="docutils literal notranslate"><span class="pre">helm</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 <span class="se">\</span>
   <span class="o">&amp;&amp;</span> chmod <span class="m">700</span> get_helm.sh <span class="se">\</span>
   <span class="o">&amp;&amp;</span> ./get_helm.sh
</pre></div>
</div>
<p>Now, add the NVIDIA Helm repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm repo add nvidia https://helm.ngc.nvidia.com/nvidia <span class="se">\</span>
   <span class="o">&amp;&amp;</span> helm repo update
</pre></div>
</div>
</section>
<section id="install-the-gpu-operator">
<h3>Install the GPU Operator<a class="headerlink" href="#install-the-gpu-operator" title="Permalink to this headline"></a></h3>
<p>The GPU Operator Helm chart offers a number of customizable options that can be configured depending on your environment.</p>
<div data-mermaid="flowchart LR
   A[&quot;Install Helm&quot;]
   --&gt;
   B[&quot;Customize options
      in Helm chart&quot;]
   --&gt;
   C[&quot;Use Helm to deploy
      the GPU Operator&quot;]"><div class="mermaid">
            flowchart LR
   A[&quot;Install Helm&quot;]
   --&gt;
   B[&quot;Customize options
      in Helm chart&quot;]
   --&gt;
   C[&quot;Use Helm to deploy
      the GPU Operator&quot;]
        </div></div><section id="chart-customization-options">
<span id="gpu-operator-helm-chart-options"></span><h4>Chart Customization Options<a class="headerlink" href="#chart-customization-options" title="Permalink to this headline"></a></h4>
<p>The following options are available when using the Helm chart. These options can be used with <code class="docutils literal notranslate"><span class="pre">--set</span></code> when installing via Helm.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 50%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ccManager.enabled</span></code></p></td>
<td><p>When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the Operator deploys NVIDIA Confidential Computing Manager for Kubernetes.
Refer to <a class="reference internal" href="gpu-operator-confidential-containers.html"><span class="doc">GPU Operator with Confidential Containers and Kata</span></a> for more information.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cdi.enabled</span></code></p></td>
<td><p>When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the Operator installs two additional runtime classes,
nvidia-cdi and nvidia-legacy, and enables the use of the Container Device Interface (CDI)
for making GPUs accessible to containers.
Using CDI aligns the Operator with the recent efforts to standardize how complex devices like GPUs
are exposed to containerized environments.</p>
<p>Pods can specify <code class="docutils literal notranslate"><span class="pre">spec.runtimeClassName</span></code> as <code class="docutils literal notranslate"><span class="pre">nvidia-cdi</span></code> to use the functionality or
specify <code class="docutils literal notranslate"><span class="pre">nvidia-legacy</span></code> to prevent using CDI to perform device injection.</p>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cdi.default</span></code></p></td>
<td><p>When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the container runtime uses CDI to perform device injection by default.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">daemonsets.annotations</span></code></p></td>
<td><p>Map of custom annotations to add to all GPU Operator managed pods.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">{}</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">daemonsets.labels</span></code></p></td>
<td><p>Map of custom labels to add to all GPU Operator managed pods.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">{}</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">driver.enabled</span></code></p></td>
<td><p>By default, the Operator deploys NVIDIA drivers as a container on the system.
Set this value to <code class="docutils literal notranslate"><span class="pre">false</span></code> when using the Operator on systems with pre-installed drivers.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">driver.repository</span></code></p></td>
<td><p>The images are downloaded from NGC. Specify another image repository when using
custom driver images.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nvcr.io/nvidia</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">driver.rdma.enabled</span></code></p></td>
<td><p>Controls whether the driver daemonset should build and load the <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">driver.rdma.useHostMofed</span></code></p></td>
<td><p>Indicate if MOFED is directly pre-installed on the host. This is used to build and load <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">driver.startupProbe</span></code></p></td>
<td><p>By default, the driver container has an initial delay of <code class="docutils literal notranslate"><span class="pre">60s</span></code> before starting liveness probes.
The probe runs the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command with a timeout duration of <code class="docutils literal notranslate"><span class="pre">60s</span></code>.
You can increase the <code class="docutils literal notranslate"><span class="pre">timeoutSeconds</span></code> duration if the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command
runs slowly in your cluster.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">60s</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">driver.usePrecompiled</span></code></p></td>
<td><p>When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the Operator attempts to deploy driver containers that have
precompiled kernel drivers.
This option is available as a technology preview feature for select operating systems.
Refer to the <a class="reference internal" href="precompiled-drivers.html"><span class="doc">precompiled driver containers</span></a> page for the supported operating systems.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">driver.version</span></code></p></td>
<td><p>Version of the NVIDIA datacenter driver supported by the Operator.</p>
<p>If you set <code class="docutils literal notranslate"><span class="pre">driver.usePrecompiled</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code>, then set this field to
a driver branch, such as <code class="docutils literal notranslate"><span class="pre">525</span></code>.</p>
</td>
<td><p>Depends on the version of the Operator. See the Component Matrix
for more information on supported drivers.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kataManager.enabled</span></code></p></td>
<td><p>The GPU Operator deploys NVIDIA Kata Manager when this field is <code class="docutils literal notranslate"><span class="pre">true</span></code>.
Refer to <a class="reference internal" href="gpu-operator-kata.html"><span class="doc">GPU Operator with Kata Containers</span></a> for more information.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mig.strategy</span></code></p></td>
<td><p>Controls the strategy to be used with MIG on supported NVIDIA GPUs. Options
are either <code class="docutils literal notranslate"><span class="pre">mixed</span></code> or <code class="docutils literal notranslate"><span class="pre">single</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">single</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">migManager.enabled</span></code></p></td>
<td><p>The MIG manager watches for changes to the MIG geometry and applies reconfiguration as needed. By
default, the MIG manager only runs on nodes with GPUs that support MIG (for e.g. A100).</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nfd.enabled</span></code></p></td>
<td><p>Deploys Node Feature Discovery plugin as a daemonset.
Set this variable to <code class="docutils literal notranslate"><span class="pre">false</span></code> if NFD is already running in the cluster.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nfd.nodefeaturerules</span></code></p></td>
<td><p>Installs node feature rules that are related to confidential computing.
NFD uses the rules to detect security features in CPUs and NVIDIA GPUs.
Set this variable to <code class="docutils literal notranslate"><span class="pre">true</span></code> when you configure the Operator for Confidential Containers.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">operator.defaultRuntime</span></code></p></td>
<td><p><strong>DEPRECATED as of v1.9</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">docker</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">operator.labels</span></code></p></td>
<td><p>Map of custom labels that will be added to all GPU Operator managed pods.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">{}</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">psp.enabled</span></code></p></td>
<td><p>The GPU operator deploys <code class="docutils literal notranslate"><span class="pre">PodSecurityPolicies</span></code> if enabled.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">toolkit.enabled</span></code></p></td>
<td><p>By default, the Operator deploys the NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code> stack)
as a container on the system. Set this value to <code class="docutils literal notranslate"><span class="pre">false</span></code> when using the Operator on systems
with pre-installed NVIDIA runtimes.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="namespace">
<h4>Namespace<a class="headerlink" href="#namespace" title="Permalink to this headline"></a></h4>
<p>Prior to GPU Operator v1.9, the operator was installed in the <code class="docutils literal notranslate"><span class="pre">default</span></code> namespace while all operands were
installed in the <code class="docutils literal notranslate"><span class="pre">gpu-operator-resources</span></code> namespace.</p>
<p>Starting with GPU Operator v1.9, both the operator and operands get installed in the same namespace.
The namespace is configurable and is determined during installation. For example, to install the GPU Operator
in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator
</pre></div>
</div>
<p>If a namespace is not specified during installation, all GPU Operator components will be installed in the
<code class="docutils literal notranslate"><span class="pre">default</span></code> namespace.</p>
</section>
<section id="operands">
<h4>Operands<a class="headerlink" href="#operands" title="Permalink to this headline"></a></h4>
<p>By default, the GPU Operator operands are deployed on all GPU worker nodes in the cluster.
GPU worker nodes are identified by the presence of the label <code class="docutils literal notranslate"><span class="pre">feature.node.kubernetes.io/pci-10de.present=true</span></code>,
where <code class="docutils literal notranslate"><span class="pre">0x10de</span></code> is the PCI vendor ID assigned to NVIDIA.</p>
<p>To disable operands from getting deployed on a GPU worker node, label the node with <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu.deploy.operands=false</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl label nodes <span class="nv">$NODE</span> nvidia.com/gpu.deploy.operands<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<section id="common-deployment-scenarios">
<h4>Common Deployment Scenarios<a class="headerlink" href="#common-deployment-scenarios" title="Permalink to this headline"></a></h4>
<p>In this section, we present some common deployment recipes when using the Helm chart to install the GPU Operator.</p>
<section id="bare-metal-passthrough-with-default-configurations-on-ubuntu">
<h5>Bare-metal/Passthrough with default configurations on Ubuntu<a class="headerlink" href="#bare-metal-passthrough-with-default-configurations-on-ubuntu" title="Permalink to this headline"></a></h5>
<p>In this scenario, the default configuration options are used:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator
</pre></div>
</div>
<p>For installing on Secure Boot systems or using Precompiled modules refer to <a class="reference internal" href="precompiled-drivers.html"><span class="doc">Precompiled Driver Containers</span></a>.</p>
</section>
<section id="bare-metal-passthrough-with-default-configurations-on-red-hat-enterprise-linux">
<h5>Bare-metal/Passthrough with default configurations on Red Hat Enterprise Linux<a class="headerlink" href="#bare-metal-passthrough-with-default-configurations-on-red-hat-enterprise-linux" title="Permalink to this headline"></a></h5>
<p>In this scenario, use the NVIDIA Container Toolkit image that is built on UBI 8:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --set toolkit-version<span class="o">=</span><span class="m">1</span>.13.4-ubi8
</pre></div>
</div>
<p>Replace the <code class="docutils literal notranslate"><span class="pre">1.13.4</span></code> value in the preceding command with the version that is supported
with the NVIDIA GPU Operator.
Refer to the <a class="reference internal" href="platform-support.html#gpu-operator-component-matrix"><span class="std std-ref">GPU Operator Component Matrix</span></a> on the platform support page.</p>
<p>When using RHEL8 with Kubernetes, SELinux must be enabled either in permissive or enforcing mode for use with the GPU Operator.
Additionally, network restricted environments are not supported.</p>
</section>
<section id="bare-metal-passthrough-with-default-configurations-on-centos">
<h5>Bare-metal/Passthrough with default configurations on CentOS<a class="headerlink" href="#bare-metal-passthrough-with-default-configurations-on-centos" title="Permalink to this headline"></a></h5>
<p>In this scenario, use the NVIDIA Container Toolkit image that is build on CentOS:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --set toolkit.version<span class="o">=</span><span class="m">1</span>.13.4-centos7
</pre></div>
</div>
<p>For CentOS 8 systems, use the UBI 8 image: <code class="docutils literal notranslate"><span class="pre">toolkit.version=1.13.4-ubi8</span></code>.</p>
<p>Replace the <code class="docutils literal notranslate"><span class="pre">1.13.4</span></code> value in the preceding command with the version that is supported with the NVIDIA GPU Operator.
Refer to the <a class="reference internal" href="platform-support.html#gpu-operator-component-matrix"><span class="std std-ref">GPU Operator Component Matrix</span></a> on the platform support page.
You can also refer to the <a class="reference external" href="https://ngc.nvidia.com/catalog/containers/nvidia:k8s:container-toolkit/tags">tags</a>
for the NVIDIA Container Toolkit image from the NVIDIA NGC Catalog.</p>
</section>
<hr class="docutils" />
<section id="nvidia-vgpu">
<h5>NVIDIA vGPU<a class="headerlink" href="#nvidia-vgpu" title="Permalink to this headline"></a></h5>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The GPU Operator with NVIDIA vGPUs requires additional steps to build a private driver image prior to install.
Refer to the document <a class="reference internal" href="install-gpu-operator-vgpu.html#install-gpu-operator-vgpu"><span class="std std-ref">NVIDIA vGPU</span></a> for detailed instructions on the workflow and required values of
the variables used in this command.</p>
</div>
<p>The command below will install the GPU Operator with its default configuration for vGPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --set driver.repository<span class="o">=</span><span class="nv">$PRIVATE_REGISTRY</span> <span class="se">\</span>
     --set driver.version<span class="o">=</span><span class="nv">$VERSION</span> <span class="se">\</span>
     --set driver.imagePullSecrets<span class="o">={</span><span class="nv">$REGISTRY_SECRET_NAME</span><span class="o">}</span> <span class="se">\</span>
     --set driver.licensingConfig.configMapName<span class="o">=</span>licensing-config
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="nvidia-ai-enterprise">
<h5>NVIDIA AI Enterprise<a class="headerlink" href="#nvidia-ai-enterprise" title="Permalink to this headline"></a></h5>
<p>Refer to <a class="reference internal" href="install-gpu-operator-nvaie.html#install-gpu-operator-nvaie"><span class="std std-ref">GPU Operator with NVIDIA AI Enterprise</span></a>.</p>
</section>
<hr class="docutils" />
<section id="bare-metal-passthrough-with-pre-installed-nvidia-drivers">
<h5>Bare-metal/Passthrough with pre-installed NVIDIA drivers<a class="headerlink" href="#bare-metal-passthrough-with-pre-installed-nvidia-drivers" title="Permalink to this headline"></a></h5>
<p>In this example, the user has already pre-installed NVIDIA drivers as part of the system image:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --set driver.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<hr class="docutils" />
</section>
<section id="bare-metal-passthrough-with-pre-installed-drivers-and-nvidia-container-toolkit">
<span id="preinstalled-drivers-and-toolkit"></span><h5>Bare-metal/Passthrough with pre-installed drivers and NVIDIA Container Toolkit<a class="headerlink" href="#bare-metal-passthrough-with-pre-installed-drivers-and-nvidia-container-toolkit" title="Permalink to this headline"></a></h5>
<p>In this example, the user has already pre-installed the NVIDIA drivers and NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>)
as part of the system image.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These steps should be followed when using the GPU Operator v1.9+ on DGX A100 systems with DGX OS 5.1+.</p>
</div>
<p>Before installing the operator, ensure that the following configurations are modified depending on the container runtime configured in your cluster.</p>
<p>Docker:</p>
<blockquote>
<div><ul>
<li><p>Update the Docker configuration to add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime. The <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime should
be setup as the default container runtime for Docker on GPU nodes. This can be done by adding the
<code class="docutils literal notranslate"><span class="pre">default-runtime</span></code> line into the Docker daemon config file, which is usually located on the system
at <code class="docutils literal notranslate"><span class="pre">/etc/docker/daemon.json</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">    &quot;default-runtime&quot;: &quot;nvidia&quot;,</span>
<span class="go">    &quot;runtimes&quot;: {</span>
<span class="go">        &quot;nvidia&quot;: {</span>
<span class="go">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span>
<span class="go">            &quot;runtimeArgs&quot;: []</span>
<span class="go">      }</span>
<span class="go">    }</span>
<span class="go">}</span>
</pre></div>
</div>
<p>Restart the Docker daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo systemctl restart docker
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Containerd:</p>
<blockquote>
<div><ul>
<li><p>Update <code class="docutils literal notranslate"><span class="pre">containerd</span></code> to use <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime and add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime configuration.
This can be done by adding below config to <code class="docutils literal notranslate"><span class="pre">/etc/containerd/config.toml</span></code> and restarting <code class="docutils literal notranslate"><span class="pre">containerd</span></code> service.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">version = 2</span>
<span class="go">[plugins]</span>
<span class="go">  [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span>
<span class="go">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]</span>
<span class="go">      default_runtime_name = &quot;nvidia&quot;</span>

<span class="go">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]</span>
<span class="go">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia]</span>
<span class="go">          privileged_without_host_devices = false</span>
<span class="go">          runtime_engine = &quot;&quot;</span>
<span class="go">          runtime_root = &quot;&quot;</span>
<span class="go">          runtime_type = &quot;io.containerd.runc.v2&quot;</span>
<span class="go">          [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia.options]</span>
<span class="go">            BinaryName = &quot;/usr/bin/nvidia-container-runtime&quot;</span>
</pre></div>
</div>
<p>Restart the Containerd daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo systemctl restart containerd
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Install the GPU operator with the following options:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
      nvidia/gpu-operator <span class="se">\</span>
      --set driver.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
      --set toolkit.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="bare-metal-passthrough-with-pre-installed-nvidia-container-toolkit-but-no-drivers">
<h5>Bare-metal/Passthrough with pre-installed NVIDIA Container Toolkit (but no drivers)<a class="headerlink" href="#bare-metal-passthrough-with-pre-installed-nvidia-container-toolkit-but-no-drivers" title="Permalink to this headline"></a></h5>
<p>In this example, the user has already pre-installed the NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>) as part of the system image.</p>
<p>Before installing the operator, ensure that the following configurations are modified depending on the container runtime configured in your cluster.</p>
<p>Docker:</p>
<blockquote>
<div><ul>
<li><p>Update the Docker configuration to add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime. The <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime should
be setup as the default container runtime for Docker on GPU nodes. This can be done by adding the
<code class="docutils literal notranslate"><span class="pre">default-runtime</span></code> line into the Docker daemon config file, which is usually located on the system
at <code class="docutils literal notranslate"><span class="pre">/etc/docker/daemon.json</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">    &quot;default-runtime&quot;: &quot;nvidia&quot;,</span>
<span class="go">    &quot;runtimes&quot;: {</span>
<span class="go">        &quot;nvidia&quot;: {</span>
<span class="go">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span>
<span class="go">            &quot;runtimeArgs&quot;: []</span>
<span class="go">      }</span>
<span class="go">    }</span>
<span class="go">}</span>
</pre></div>
</div>
<p>Restart the Docker daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo systemctl restart docker
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Containerd:</p>
<blockquote>
<div><ul>
<li><p>Update <code class="docutils literal notranslate"><span class="pre">containerd</span></code> to use <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime and add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime configuration.
This can be done by adding below config to <code class="docutils literal notranslate"><span class="pre">/etc/containerd/config.toml</span></code> and restarting <code class="docutils literal notranslate"><span class="pre">containerd</span></code> service.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">version = 2</span>
<span class="go">[plugins]</span>
<span class="go">  [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span>
<span class="go">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]</span>
<span class="go">      default_runtime_name = &quot;nvidia&quot;</span>

<span class="go">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]</span>
<span class="go">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia]</span>
<span class="go">          privileged_without_host_devices = false</span>
<span class="go">          runtime_engine = &quot;&quot;</span>
<span class="go">          runtime_root = &quot;&quot;</span>
<span class="go">          runtime_type = &quot;io.containerd.runc.v2&quot;</span>
<span class="go">          [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia.options]</span>
<span class="go">            BinaryName = &quot;/usr/bin/nvidia-container-runtime&quot;</span>
</pre></div>
</div>
<p>Restart the Containerd daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo systemctl restart containerd
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Configure toolkit to use the <code class="docutils literal notranslate"><span class="pre">root</span></code> directory of the driver installation as <code class="docutils literal notranslate"><span class="pre">/run/nvidia/driver</span></code>, which is the path mounted by driver container.</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo sed -i <span class="s1">&#39;s/^#root/root/&#39;</span> /etc/nvidia-container-runtime/config.toml
</pre></div>
</div>
</div></blockquote>
<p>Once these steps are complete, now install the GPU operator with the following options (which will provision a driver):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --set toolkit.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="custom-driver-image-based-off-a-specific-driver-version">
<h5>Custom driver image (based off a specific driver version)<a class="headerlink" href="#custom-driver-image-based-off-a-specific-driver-version" title="Permalink to this headline"></a></h5>
<p>If you want to use custom driver container images (for e.g. using 465.27), then
you would need to build a new driver container image. Follow these steps:</p>
<ul>
<li><p>Rebuild the driver container by specifying the <code class="docutils literal notranslate"><span class="pre">$DRIVER_VERSION</span></code> argument when building the Docker image. For
reference, the driver container Dockerfiles are available on the Git repo <a class="reference external" href="https://gitlab.com/nvidia/container-images/driver">here</a></p></li>
<li><p>Build the container using the appropriate Dockerfile. For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>docker build --pull -t <span class="se">\</span>
    --build-arg <span class="nv">DRIVER_VERSION</span><span class="o">=</span><span class="m">455</span>.28 <span class="se">\</span>
    nvidia/driver:455.28-ubuntu20.04 <span class="se">\</span>
    --file Dockerfile .
</pre></div>
</div>
<p>Ensure that the driver container is tagged as shown in the example by using the <code class="docutils literal notranslate"><span class="pre">driver:&lt;version&gt;-&lt;os&gt;</span></code> schema.</p>
</li>
<li><p>Specify the new driver image and repository by overriding the defaults in
the Helm install command. For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --set driver.repository<span class="o">=</span>docker.io/nvidia <span class="se">\</span>
     --set driver.version<span class="o">=</span><span class="s2">&quot;465.27&quot;</span>
</pre></div>
</div>
</li>
</ul>
<p>Note that these instructions are provided for reference and evaluation purposes.
Not using the standard releases of the GPU Operator from NVIDIA would mean limited
support for such custom configurations.</p>
<hr class="docutils" />
</section>
<section id="custom-configuration-for-runtime-containerd">
<span id="custom-runtime-options"></span><h5>Custom configuration for runtime containerd<a class="headerlink" href="#custom-configuration-for-runtime-containerd" title="Permalink to this headline"></a></h5>
<p>When you use containerd as the container runtime, the following configuration
options are used with the container-toolkit deployed with GPU Operator:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">toolkit</span><span class="p">:</span><span class="w"></span>
<span class="w">   </span><span class="nt">env</span><span class="p">:</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_CONFIG</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/etc/containerd/config.toml</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SOCKET</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/run/containerd/containerd.sock</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_RUNTIME_CLASS</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SET_AS_DEFAULT</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
</pre></div>
</div>
<p>These options are defined as follows:</p>
<blockquote>
<div><ul>
<li><dl>
<dt><strong>CONTAINERD_CONFIG</strong><span class="classifier">The path on the host to the <code class="docutils literal notranslate"><span class="pre">containerd</span></code> config</span></dt><dd><p>you would like to have updated with support for the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>.
By default this will point to <code class="docutils literal notranslate"><span class="pre">/etc/containerd/config.toml</span></code> (the default
location for <code class="docutils literal notranslate"><span class="pre">containerd</span></code>). It should be customized if your <code class="docutils literal notranslate"><span class="pre">containerd</span></code>
installation is not in the default location.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>CONTAINERD_SOCKET</strong><span class="classifier">The path on the host to the socket file used to</span></dt><dd><p>communicate with <code class="docutils literal notranslate"><span class="pre">containerd</span></code>. The operator will use this to send a
<code class="docutils literal notranslate"><span class="pre">SIGHUP</span></code> signal to the <code class="docutils literal notranslate"><span class="pre">containerd</span></code> daemon to reload its config. By
default this will point to <code class="docutils literal notranslate"><span class="pre">/run/containerd/containerd.sock</span></code>
(the default location for <code class="docutils literal notranslate"><span class="pre">containerd</span></code>). It should be customized if
your <code class="docutils literal notranslate"><span class="pre">containerd</span></code> installation is not in the default location.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>CONTAINERD_RUNTIME_CLASS</strong><span class="classifier">The name of the</span></dt><dd><p><a class="reference external" href="https://kubernetes.io/docs/concepts/containers/runtime-class">Runtime Class</a>
you would like to associate with the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>.
Pods launched with a <code class="docutils literal notranslate"><span class="pre">runtimeClassName</span></code> equal to CONTAINERD_RUNTIME_CLASS
will always run with the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>. The default
CONTAINERD_RUNTIME_CLASS is <code class="docutils literal notranslate"><span class="pre">nvidia</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>CONTAINERD_SET_AS_DEFAULT</strong><span class="classifier">A flag indicating whether you want to set</span></dt><dd><p><code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code> as the default runtime used to launch all
containers. When set to false, only containers in pods with a <code class="docutils literal notranslate"><span class="pre">runtimeClassName</span></code>
equal to CONTAINERD_RUNTIME_CLASS will be run with the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>.
The default value is <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p class="rubric">Rancher Kubernetes Engine 2</p>
<p>For Rancher Kubernetes Engine 2 (RKE2), set the following in the <cite>ClusterPolicy</cite>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">toolkit</span><span class="p">:</span><span class="w"></span>
<span class="w">   </span><span class="nt">env</span><span class="p">:</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_CONFIG</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SOCKET</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/run/k3s/containerd/containerd.sock</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_RUNTIME_CLASS</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SET_AS_DEFAULT</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="w"></span>
</pre></div>
</div>
<p>These options can be passed to GPU Operator during install time as below.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">helm install gpu-operator -n gpu-operator --create-namespace \</span>
<span class="go">  nvidia/gpu-operator $HELM_OPTIONS \</span>
<span class="go">    --set toolkit.env[0].name=CONTAINERD_CONFIG \</span>
<span class="go">    --set toolkit.env[0].value=/var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl \</span>
<span class="go">    --set toolkit.env[1].name=CONTAINERD_SOCKET \</span>
<span class="go">    --set toolkit.env[1].value=/run/k3s/containerd/containerd.sock \</span>
<span class="go">    --set toolkit.env[2].name=CONTAINERD_RUNTIME_CLASS \</span>
<span class="go">    --set toolkit.env[2].value=nvidia \</span>
<span class="go">    --set toolkit.env[3].name=CONTAINERD_SET_AS_DEFAULT \</span>
<span class="go">    --set-string toolkit.env[3].value=true</span>
</pre></div>
</div>
<p class="rubric">MicroK8s</p>
<p>For MicroK8s, set the following in the <cite>ClusterPolicy</cite>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">toolkit</span><span class="p">:</span><span class="w"></span>
<span class="w">   </span><span class="nt">env</span><span class="p">:</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_CONFIG</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/var/snap/microk8s/current/args/containerd-template.toml</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SOCKET</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/var/snap/microk8s/common/run/containerd.sock</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_RUNTIME_CLASS</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia</span><span class="w"></span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SET_AS_DEFAULT</span><span class="w"></span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="w"></span>
</pre></div>
</div>
<p>These options can be passed to GPU Operator during install time as below.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">helm install gpu-operator -n gpu-operator --create-namespace \</span>
<span class="go">  nvidia/gpu-operator $HELM_OPTIONS \</span>
<span class="go">    --set toolkit.env[0].name=CONTAINERD_CONFIG \</span>
<span class="go">    --set toolkit.env[0].value=/var/snap/microk8s/current/args/containerd-template.toml \</span>
<span class="go">    --set toolkit.env[1].name=CONTAINERD_SOCKET \</span>
<span class="go">    --set toolkit.env[1].value=/var/snap/microk8s/common/run/containerd.sock \</span>
<span class="go">    --set toolkit.env[2].name=CONTAINERD_RUNTIME_CLASS \</span>
<span class="go">    --set toolkit.env[2].value=nvidia \</span>
<span class="go">    --set toolkit.env[3].name=CONTAINERD_SET_AS_DEFAULT \</span>
<span class="go">    --set-string toolkit.env[3].value=true</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="proxy-environments">
<h5>Proxy Environments<a class="headerlink" href="#proxy-environments" title="Permalink to this headline"></a></h5>
<p>Refer to the section <a class="reference internal" href="install-gpu-operator-proxy.html#install-gpu-operator-proxy"><span class="std std-ref">Install GPU Operator in Proxy Environments</span></a> for more information on how to install the Operator on clusters
behind a HTTP proxy.</p>
</section>
<hr class="docutils" />
<section id="air-gapped-environments">
<h5>Air-gapped Environments<a class="headerlink" href="#air-gapped-environments" title="Permalink to this headline"></a></h5>
<p>Refer to the section <a class="reference internal" href="install-gpu-operator-air-gapped.html#install-gpu-operator-air-gapped"><span class="std std-ref">Install NVIDIA GPU Operator in Air-Gapped Environments</span></a> for more information on how to install the Operator
in air-gapped environments.</p>
</section>
<hr class="docutils" />
<section id="multi-instance-gpu-mig">
<h5>Multi-Instance GPU (MIG)<a class="headerlink" href="#multi-instance-gpu-mig" title="Permalink to this headline"></a></h5>
<p>Refer to the document <a class="reference internal" href="gpu-operator-mig.html#install-gpu-operator-mig"><span class="std std-ref">GPU Operator with MIG</span></a> for more information on how use the Operator with Multi-Instance GPU (MIG)
on NVIDIA Ampere products.
For information about configuring MIG support for the NVIDIA GPU Operator in an OpenShift Container Platform cluster,
refer to <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/mig-ocp.html" title="(in NVIDIA GPU Operator on Red Hat OpenShift Container Platform)"><span>MIG Support in OpenShift Container Platform</span></a> for more information.</p>
</section>
<hr class="docutils" />
<section id="kubevirt-openshift-virtualization">
<h5>KubeVirt / OpenShift Virtualization<a class="headerlink" href="#kubevirt-openshift-virtualization" title="Permalink to this headline"></a></h5>
<p>Refer to the document <a class="reference internal" href="gpu-operator-kubevirt.html#gpu-operator-kubevirt"><span class="std std-ref">GPU Operator with KubeVirt</span></a> for more information on how to use the GPU Operator to provision GPU nodes for running KubeVirt virtual machines with access to GPU.
For guidance on using the GPU Operator with OpenShift Virtualization, refer to the document <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/openshift-virtualization.html" title="(in NVIDIA GPU Operator on Red Hat OpenShift Container Platform)"><span>NVIDIA GPU Operator with OpenShift Virtualization</span></a>.</p>
</section>
<section id="outdated-kernels">
<h5>Outdated Kernels<a class="headerlink" href="#outdated-kernels" title="Permalink to this headline"></a></h5>
<p>Refer to the section <a class="reference internal" href="install-gpu-operator-outdated-kernels.html#install-gpu-operator-outdated-kernels"><span class="std std-ref">Considerations when Installing with Outdated Kernels in Cluster</span></a> for more information on how to install the Operator successfully
when nodes in the cluster are not running the latest kernel</p>
</section>
</section>
<hr class="docutils" />
<section id="verify-gpu-operator-install">
<h4>Verify GPU Operator Install<a class="headerlink" href="#verify-gpu-operator-install" title="Permalink to this headline"></a></h4>
<p>Once the Helm chart is installed, check the status of the pods to ensure all the containers are running and the validation is complete:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pods -n gpu-operator
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                                          READY   STATUS      RESTARTS   AGE</span>
<span class="go">gpu-feature-discovery-crrsq                                   1/1     Running     0          60s</span>
<span class="go">gpu-operator-7fb75556c7-x8spj                                 1/1     Running     0          5m13s</span>
<span class="go">gpu-operator-node-feature-discovery-master-58d884d5cc-w7q7b   1/1     Running     0          5m13s</span>
<span class="go">gpu-operator-node-feature-discovery-worker-6rht2              1/1     Running     0          5m13s</span>
<span class="go">gpu-operator-node-feature-discovery-worker-9r8js              1/1     Running     0          5m13s</span>
<span class="go">nvidia-container-toolkit-daemonset-lhgqf                      1/1     Running     0          4m53s</span>
<span class="go">nvidia-cuda-validator-rhvbb                                   0/1     Completed   0          54s</span>
<span class="go">nvidia-dcgm-5jqzg                                             1/1     Running     0          60s</span>
<span class="go">nvidia-dcgm-exporter-h964h                                    1/1     Running     0          60s</span>
<span class="go">nvidia-device-plugin-daemonset-d9ntc                          1/1     Running     0          60s</span>
<span class="go">nvidia-device-plugin-validator-cm2fd                          0/1     Completed   0          48s</span>
<span class="go">nvidia-driver-daemonset-5xj6g                                 1/1     Running     0          4m53s</span>
<span class="go">nvidia-mig-manager-89z9b                                      1/1     Running     0          4m53s</span>
<span class="go">nvidia-operator-validator-bwx99                               1/1     Running     0          58s</span>
</pre></div>
</div>
<p>We can now proceed to running some sample GPU workloads to verify that the Operator (and its components) are working correctly.</p>
</section>
</section>
</section>
<section id="running-sample-gpu-applications">
<h2>Running Sample GPU Applications<a class="headerlink" href="#running-sample-gpu-applications" title="Permalink to this headline"></a></h2>
<section id="cuda-vectoradd">
<h3>CUDA VectorAdd<a class="headerlink" href="#cuda-vectoradd" title="Permalink to this headline"></a></h3>
<p>In the first example, let’s run a simple CUDA sample, which adds two vectors together:</p>
<ol class="arabic">
<li><p>Create a file, such as <code class="docutils literal notranslate"><span class="pre">cuda-vectoradd.yaml</span></code>, with contents like the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Pod</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cuda-vectoradd</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OnFailure</span><span class="w"></span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cuda-vectoradd</span><span class="w"></span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04&quot;</span><span class="w"></span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Run the pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f cuda-vectoradd.yaml
</pre></div>
</div>
<p>The pod starts, runs the <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> command, and then exits.</p>
</li>
<li><p>View the logs from the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl logs pod/cuda-vectoradd
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">[Vector addition of 50000 elements]</span>
<span class="go">Copy input data from the host memory to the CUDA device</span>
<span class="go">CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">Copy output data from the CUDA device to the host memory</span>
<span class="go">Test PASSED</span>
<span class="go">Done</span>
</pre></div>
</div>
</li>
<li><p>Removed the stopped pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl delete -f cuda-vectoradd.yaml
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">pod &quot;cuda-vectoradd&quot; deleted</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="jupyter-notebook">
<h3>Jupyter Notebook<a class="headerlink" href="#jupyter-notebook" title="Permalink to this headline"></a></h3>
<p>You can perform the following steps to deploy Jupyter Notebook in your cluster:</p>
<ol class="arabic">
<li><p>Create a file, such as <code class="docutils literal notranslate"><span class="pre">tf-notebook.yaml</span></code>, with contents like the following example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Service</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tf-notebook</span><span class="w"></span>
<span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tf-notebook</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">NodePort</span><span class="w"></span>
<span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">80</span><span class="w"></span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http</span><span class="w"></span>
<span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8888</span><span class="w"></span>
<span class="w">    </span><span class="nt">nodePort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30001</span><span class="w"></span>
<span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tf-notebook</span><span class="w"></span>
<span class="nn">---</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Pod</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tf-notebook</span><span class="w"></span>
<span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tf-notebook</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">securityContext</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">fsGroup</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"></span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tf-notebook</span><span class="w"></span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tensorflow/tensorflow:latest-gpu-jupyter</span><span class="w"></span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8888</span><span class="w"></span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">notebook</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Apply the manifest to deploy the pod and start the service:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f tf-notebook.yaml
</pre></div>
</div>
</li>
<li><p>Check the pod status:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pod tf-notebook
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE   NAME          READY   STATUS      RESTARTS   AGE</span>
<span class="go">default     tf-notebook   1/1     Running     0          3m45s</span>
</pre></div>
</div>
</li>
<li><p>Because the manifest includes a service, get the external port for the notebook:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get svc tf-notebook
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)       AGE</span>
<span class="go">tf-notebook   NodePort    10.106.229.20   &lt;none&gt;        80:30001/TCP  4m41s</span>
</pre></div>
</div>
</li>
<li><p>Get the token for the Jupyter notebook:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl logs tf-notebook
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">[I 21:50:23.188 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret</span>
<span class="go">[I 21:50:23.390 NotebookApp] Serving notebooks from local directory: /tf</span>
<span class="go">[I 21:50:23.391 NotebookApp] The Jupyter Notebook is running at:</span>
<span class="go">[I 21:50:23.391 NotebookApp] http://tf-notebook:8888/?token=3660c9ee9b225458faaf853200bc512ff2206f635ab2b1d9</span>
<span class="go">[I 21:50:23.391 NotebookApp]  or http://127.0.0.1:8888/?token=3660c9ee9b225458faaf853200bc512ff2206f635ab2b1d9</span>
<span class="go">[I 21:50:23.391 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</span>
<span class="go">[C 21:50:23.394 NotebookApp]</span>

<span class="go">To access the notebook, open this file in a browser:</span>
<span class="go">   file:///root/.local/share/jupyter/runtime/nbserver-1-open.html</span>
<span class="go">Or copy and paste one of these URLs:</span>
<span class="go">   http://tf-notebook:8888/?token=3660c9ee9b225458faaf853200bc512ff2206f635ab2b1d9</span>
<span class="go">or http://127.0.0.1:8888/?token=3660c9ee9b225458faaf853200bc512ff2206f635ab2b1d9</span>
</pre></div>
</div>
</li>
</ol>
<p>The notebook should now be accessible from your browser at this URL:
<a class="reference external" href="http://your-machine-ip:30001/?token=3660c9ee9b225458faaf853200bc512ff2206f635ab2b1d9">http://your-machine-ip:30001/?token=3660c9ee9b225458faaf853200bc512ff2206f635ab2b1d9</a>.</p>
</section>
</section>
<section id="demo">
<h2>Demo<a class="headerlink" href="#demo" title="Permalink to this headline"></a></h2>
<p>Check out the demo below where we scale GPU nodes in a K8s cluster using the GPU Operator:</p>
<a class="reference internal image-reference" href="_images/gpu-operator-demo.gif"><img alt="_images/gpu-operator-demo.gif" src="_images/gpu-operator-demo.gif" style="width: 1440px;" /></a>
</section>
<section id="gpu-telemetry">
<h2>GPU Telemetry<a class="headerlink" href="#gpu-telemetry" title="Permalink to this headline"></a></h2>
<p>To gather GPU telemetry in Kubernetes, the GPU Operator deploys the <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>. <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>, based
on <a class="reference external" href="https://developer.nvidia.com/dcgm">DCGM</a> exposes GPU metrics for Prometheus and can be visualized using Grafana. <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code> is architected to take advantage of
<code class="docutils literal notranslate"><span class="pre">KubeletPodResources</span></code> <a class="reference external" href="https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/">API</a> and exposes GPU metrics in a format that can be
scraped by Prometheus.</p>
<section id="custom-metrics-config">
<h3>Custom Metrics Config<a class="headerlink" href="#custom-metrics-config" title="Permalink to this headline"></a></h3>
<p>With GPU Operator users can customize the metrics to be collected by <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>. Below are the steps for this</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Fetch the metrics file and save as dcgm-metrics.csv</p></li>
</ol>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl https://raw.githubusercontent.com/NVIDIA/dcgm-exporter/main/etc/dcp-metrics-included.csv &gt; dcgm-metrics.csv
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>Edit the metrics file as required to add/remove any metrics to be collected.</p></li>
<li><p>Create a Namespace <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> if one is not already present.</p></li>
</ol>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create namespace gpu-operator
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="4">
<li><p>Create a ConfigMap using the file edited above.</p></li>
</ol>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create configmap metrics-config -n gpu-operator --from-file<span class="o">=</span>dcgm-metrics.csv
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="5">
<li><p>Install GPU Operator with additional options <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">dcgmExporter.config.name=metrics-config</span></code> and
<code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">dcgmExporter.env[0].name=DCGM_EXPORTER_COLLECTORS</span> <span class="pre">--set</span> <span class="pre">dcgmExporter.env[0].value=/etc/dcgm-exporter/dcgm-metrics.csv</span></code></p></li>
</ol>
</div></blockquote>
</section>
<section id="collecting-metrics-on-nvidia-dgx-a100-with-dgx-os">
<h3>Collecting Metrics on NVIDIA DGX A100 with DGX OS<a class="headerlink" href="#collecting-metrics-on-nvidia-dgx-a100-with-dgx-os" title="Permalink to this headline"></a></h3>
<p>NVIDIA DGX systems running with DGX OS bundles drivers, DCGM, etc. in the system image and have <cite>nv-hostengine</cite> running already.
To avoid any compatibility issues, it is recommended to have <cite>dcgm-exporter</cite> connect to the existing <cite>nv-hostengine</cite> daemon to gather/publish
GPU telemetry data.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The <cite>dcgm-exporter</cite> container image includes a DCGM client library (<code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) to communicate with
<cite>nv-hostengine</cite>. In this deployment scenario we have <cite>dcgm-exporter</cite> (or rather <code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) connect
to an existing <cite>nv-hostengine</cite> running on the host. The DCGM client library uses an internal protocol to exchange
information with <cite>nv-hostengine</cite>. To avoid any potential incompatibilities between the container image’s DCGM client library
and the host’s <cite>nv-hostengine</cite>, it is strongly recommended to use a version of DCGM on which <cite>dcgm-exporter</cite> is based is
greater than or equal to (but not less than) the version of DCGM running on the host. This can be easily determined by
comparing the version tags of the <cite>dcgm-exporter</cite> image and by running <code class="docutils literal notranslate"><span class="pre">nv-hostengine</span> <span class="pre">--version</span></code> on the host.</p>
</div>
<p>In this scenario, we need to set <code class="docutils literal notranslate"><span class="pre">DCGM_REMOTE_HOSTENGINE_INFO</span></code> to <code class="docutils literal notranslate"><span class="pre">localhost:5555</span></code> for <cite>dcgm-exporter</cite> to connect to <cite>nv-hostengine</cite> running on the host.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl patch clusterpolicy/cluster-policy --type<span class="o">=</span><span class="s1">&#39;json&#39;</span> -p<span class="o">=</span><span class="s1">&#39;[{&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/spec/dcgmExporter/env/-&quot;, &quot;value&quot;:{&quot;name&quot;:&quot;DCGM_REMOTE_HOSTENGINE_INFO&quot;, &quot;value&quot;:&quot;localhost:5555&quot;}}]&#39;</span>
</pre></div>
</div>
<p>Verify <cite>dcgm-exporter</cite> pod is running after this change</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pods -l <span class="nv">app</span><span class="o">=</span>nvidia-dcgm-exporter --all-namespaces
</pre></div>
</div>
<p>Refer to
<a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/latest/kube-prometheus.html">Setting up Prometheus</a>
to complete the installation.</p>
</section>
</section>
<section id="upgrading-the-gpu-operator">
<span id="operator-upgrades"></span><h2>Upgrading the GPU Operator<a class="headerlink" href="#upgrading-the-gpu-operator" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Prerequisites<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<ul>
<li><p>If your cluster uses Pod Security Admission (PSA) to restrict the behavior of pods,
label the namespace for the Operator to set the enforcement policy to privileged:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl label --overwrite ns gpu-operator pod-security.kubernetes.io/enforce<span class="o">=</span>privileged
</pre></div>
</div>
</li>
</ul>
</section>
<section id="using-helm">
<h3>Using Helm<a class="headerlink" href="#using-helm" title="Permalink to this headline"></a></h3>
<p>The GPU Operator supports dynamic updates to existing resources.
This ability enables the GPU Operator to ensure settings from the cluster policy specification are always applied and current.</p>
<p>Because Helm does not <a class="reference external" href="https://helm.sh/docs/chart_best_practices/custom_resource_definitions/#some-caveats-and-explanations">support</a> automatic upgrade of existing CRDs,
you can upgrade the GPU Operator chart manually or by enabling a Helm hook.</p>
<section id="option-1-manually-upgrade-crd">
<h4>Option 1 - manually upgrade CRD<a class="headerlink" href="#option-1-manually-upgrade-crd" title="Permalink to this headline"></a></h4>
<blockquote>
<div><div data-mermaid="flowchart LR

   A[&quot;Update CRD from
     the latest chart&quot;]
   --&gt;
   B[&quot;Upgrade by
     using Helm&quot;]"><div class="mermaid">
            flowchart LR

   A[&quot;Update CRD from
     the latest chart&quot;]
   --&gt;
   B[&quot;Upgrade by
     using Helm&quot;]
        </div></div></div></blockquote>
<p>With this workflow, all existing GPU operator resources are updated inline and the cluster policy resource is patched with updates from <code class="docutils literal notranslate"><span class="pre">values.yaml</span></code>.</p>
<ol class="arabic">
<li><p>Specify the Operator release tag in an environment variable:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span> <span class="nv">RELEASE_TAG</span><span class="o">=</span>v23.9.0
</pre></div>
</div>
</li>
<li><p>Apply the custom resource definitions for the cluster policy and NVIDIA driver:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f <span class="se">\</span>
    https://gitlab.com/nvidia/kubernetes/gpu-operator/-/raw/<span class="nv">$RELEASE_TAG</span>/deployments/gpu-operator/crds/nvidia.com_clusterpolicies_crd.yaml

<span class="gp">$ </span>kubectl apply -f <span class="se">\</span>
    https://gitlab.com/nvidia/kubernetes/gpu-operator/-/raw/<span class="nv">$RELEASE_TAG</span>/deployments/gpu-operator/crds/nvidia.com_nvidiadrivers.yaml
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">customresourcedefinition.apiextensions.k8s.io/clusterpolicies.nvidia.com configured</span>
<span class="go">customresourcedefinition.apiextensions.k8s.io/nvidiadrivers.nvidia.com created</span>
</pre></div>
</div>
</li>
<li><p>Apply the custom resource definition for Node Feature Discovery:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f <span class="se">\</span>
    https://gitlab.com/nvidia/kubernetes/gpu-operator/-/raw/<span class="nv">$RELEASE_TAG</span>/deployments/gpu-operator/charts/node-feature-discovery/crds/nfd-api-crds.yaml
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">customresourcedefinition.apiextensions.k8s.io/nodefeaturerules.nfd.k8s-sigs.io configured</span>
</pre></div>
</div>
</li>
<li><p>Update the information about the Operator chart:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm repo update nvidia
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">Hang tight while we grab the latest from your chart repositories...</span>
<span class="go">...Successfully got an update from the &quot;nvidia&quot; chart repository</span>
<span class="go">Update Complete. ⎈Happy Helming!⎈</span>
</pre></div>
</div>
</li>
<li><p>Fetch the values from the chart:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm show values nvidia/gpu-operator --version<span class="o">=</span><span class="nv">$RELEASE_TAG</span> &gt; values-<span class="nv">$RELEASE_TAG</span>.yaml
</pre></div>
</div>
</li>
<li><p>Update the values file as needed.</p></li>
<li><p>Upgrade the Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm upgrade gpu-operator nvidia/gpu-operator -n gpu-operator -f values-<span class="nv">$RELEASE_TAG</span>.yaml
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">Release &quot;gpu-operator&quot; has been upgraded. Happy Helming!</span>
<span class="go">NAME: gpu-operator</span>
<span class="go">LAST DEPLOYED: Thu Apr 20 15:05:52 2023</span>
<span class="go">NAMESPACE: gpu-operator</span>
<span class="go">STATUS: deployed</span>
<span class="go">REVISION: 2</span>
<span class="go">TEST SUITE: None</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="option-2-auto-upgrade-crd-using-helm-hook">
<h4>Option 2 - auto upgrade CRD using Helm hook<a class="headerlink" href="#option-2-auto-upgrade-crd-using-helm-hook" title="Permalink to this headline"></a></h4>
<p>Starting with GPU Operator v22.09, a <code class="docutils literal notranslate"><span class="pre">pre-upgrade</span></code> Helm <a class="reference external" href="https://helm.sh/docs/topics/charts_hooks/#the-available-hooks">hook</a> is utilized to automatically upgrade to latest CRD.
A new parameter <code class="docutils literal notranslate"><span class="pre">operator.upgradeCRD</span></code> is added to to trigger this hook during GPU Operator upgrade using Helm. This is disabled by default.
This parameter needs to be set using <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">operator.upgradeCRD=true</span></code> option during upgrade command as below.</p>
<ol class="arabic">
<li><p>Specify the Operator release tag in an environment variable:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span> <span class="nv">RELEASE_TAG</span><span class="o">=</span>v23.9.0
</pre></div>
</div>
</li>
<li><p>Update the information about the Operator chart:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm repo update nvidia
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">Hang tight while we grab the latest from your chart repositories...</span>
<span class="go">...Successfully got an update from the &quot;nvidia&quot; chart repository</span>
<span class="go">Update Complete. ⎈Happy Helming!⎈</span>
</pre></div>
</div>
</li>
<li><p>Fetch the values from the chart:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm show values nvidia/gpu-operator --version<span class="o">=</span><span class="nv">$RELEASE_TAG</span> &gt; values-<span class="nv">$RELEASE_TAG</span>.yaml
</pre></div>
</div>
</li>
<li><p>Update the values file as needed.</p></li>
<li><p>Upgrade the Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm upgrade gpu-operator nvidia/gpu-operator -n gpu-operator <span class="se">\</span>
    --set operator.upgradeCRD<span class="o">=</span><span class="nb">true</span> --disable-openapi-validation -f values-<span class="nv">$RELEASE_TAG</span>.yaml
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Option <code class="docutils literal notranslate"><span class="pre">--disable-openapi-validation</span></code> is required in this case so that Helm will not try to validate if CR instance from the new chart is valid as per old CRD.
Since CR instance in the Chart is valid for the upgraded CRD, this will be compatible.</p></li>
<li><p>Helm hooks used with the GPU Operator use the operator image itself. If operator image itself cannot be pulled successfully (either due to network error or an invalid NGC registry secret in case of NVAIE), hooks will fail.
In this case, chart needs to be deleted using <code class="docutils literal notranslate"><span class="pre">--no-hooks</span></code> option to avoid deletion to be hung on hook failures.</p></li>
</ul>
</div>
</li>
</ol>
</section>
<section id="cluster-policy-updates">
<h4>Cluster Policy Updates<a class="headerlink" href="#cluster-policy-updates" title="Permalink to this headline"></a></h4>
<p>The GPU Operator also supports dynamic updates to the <code class="docutils literal notranslate"><span class="pre">ClusterPolicy</span></code> CustomResource using <code class="docutils literal notranslate"><span class="pre">kubectl</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl edit clusterpolicy
</pre></div>
</div>
<p>After the edits are complete, Kubernetes will automatically apply the updates to cluster.</p>
</section>
<section id="additional-controls-for-driver-upgrades">
<h4>Additional Controls for Driver Upgrades<a class="headerlink" href="#additional-controls-for-driver-upgrades" title="Permalink to this headline"></a></h4>
<p>While most of the GPU Operator managed daemonsets can be upgraded seamlessly, the NVIDIA driver daemonset has special considerations.
Refer to <a class="reference internal" href="gpu-driver-upgrades.html#gpu-driver-upgrades"><span class="std std-ref">GPU Driver Upgrades</span></a> for more information.</p>
</section>
</section>
<section id="using-olm-in-openshift">
<h3>Using OLM in OpenShift<a class="headerlink" href="#using-olm-in-openshift" title="Permalink to this headline"></a></h3>
<p>For upgrading the GPU Operator when running in OpenShift, refer to the official documentation on upgrading installed operators:
<a class="reference external" href="https://docs.openshift.com/container-platform/4.8/operators/admin/olm-upgrading-operators.html">https://docs.openshift.com/container-platform/4.8/operators/admin/olm-upgrading-operators.html</a></p>
</section>
</section>
<section id="uninstall">
<h2>Uninstall<a class="headerlink" href="#uninstall" title="Permalink to this headline"></a></h2>
<p>Perform the following steps to uninstall the Operator.</p>
<ol class="arabic">
<li><p>Optional: List and delete NVIDIA driver custom resources.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get nvidiadrivers
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">NAME          STATUS   AGE</span>
<span class="go">demo-gold     ready    2023-10-16T17:57:12Z</span>
<span class="go">demo-silver   ready    2023-10-16T17:57:12Z</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl delete nvidiadriver demo-gold
<span class="gp">$ </span>kubectl delete nvidiadriver demo-silver
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl delete crd nvidiadrivers.nvidia.com
</pre></div>
</div>
</li>
<li><p>Delete the Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm delete -n gpu-operator <span class="k">$(</span>helm list -n gpu-operator <span class="p">|</span> grep gpu-operator <span class="p">|</span> awk <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span>
</pre></div>
</div>
</li>
<li><p>Optional: List the pods in the Operator namespace to confirm the pods are deleted or in the process of deleting:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pods -n gpu-operator
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">No resources found.</span>
</pre></div>
</div>
</li>
</ol>
<p>By default, Helm does not <a class="reference external" href="https://helm.sh/docs/chart_best_practices/custom_resource_definitions/#some-caveats-and-explanations">support</a> deletion of existing CRDs when you delete the chart.
Thus the <code class="docutils literal notranslate"><span class="pre">clusterpolicy</span></code> CRD and <code class="docutils literal notranslate"><span class="pre">nvidiadrivers</span></code> CRD will still remain, by default.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get crds -A <span class="p">|</span> grep -i clusterpolicies.nvidia.com
</pre></div>
</div>
<p>To overcome this, a <code class="docutils literal notranslate"><span class="pre">post-delete</span></code> <a class="reference external" href="https://helm.sh/docs/topics/charts_hooks/#the-available-hooks">hook</a> is used in the GPU Operator to perform the CRD cleanup. A new parameter <code class="docutils literal notranslate"><span class="pre">operator.cleanupCRD</span></code>
is added to enable this hook. This is disabled by default. This parameter needs to be enabled with <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">operator.cleanupCRD=true</span></code> during install or upgrade for automatic CRD cleanup to happen on chart deletion.</p>
<p>Alternatively, delete the custom resource definition:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl delete crd clusterpolicies.nvidia.com
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li><p>After uninstalling the Operator, the NVIDIA driver modules might still be loaded.
Either reboot the node or unload them using the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo rmmod nvidia_modeset nvidia_uvm nvidia
</pre></div>
</div>
</li>
<li><p>Helm hooks used with the GPU Operator use the Operator image itself.
If the Operator image cannot be pulled successfully (either due to network error or an invalid NGC registry secret in case of NVAIE), hooks will fail.
In this case, delete the chart and specify the <code class="docutils literal notranslate"><span class="pre">--no-hooks</span></code> argument to avoid hanging on hook failures.</p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="overview.html" class="btn btn-neutral float-left" title="About the NVIDIA GPU Operator" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="platform-support.html" class="btn btn-neutral float-right" title="Platform Support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2023, NVIDIA.
      <span class="lastupdated">Last updated on Nov 30, 2023.
      </span></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 



</body>
</html>