<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Time-slicing NVIDIA GPUs in OpenShift &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/archive/22.9.0/openshift/time-slicing-gpus-in-openshift.html"/>
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
        <script src="../../../../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../../../../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="NVIDIA GPU Operator with OpenShift Virtualization" href="nvidia-gpu-operator-openshift-virtualization-vgpu-enablement.html" />
    <link rel="prev" title="Enable the GPU Operator Dashboard" href="enable-gpu-op-dashboard.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../../../../contents.html">
            <img src="../../../../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../openshift/contents.html">GPU Operator on OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix.html">Advanced Configurations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../archive.html">Archive</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id1">22.9.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id2">22.9.1</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../archive.html#id3">22.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id4">1.11.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id5">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id6">1.10.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id7">1.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id8">1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id9">1.8</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../kubernetes/install-k8s.html">Install Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kubernetes/mig-k8s.html">MIG Support in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kubernetes/anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../mig/mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mig/mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../contents.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../archive.html">Archive</a> &raquo;</li>
          <li><a href="contents.html">GPU Operator on OpenShift</a> &raquo;</li>
      <li>Time-slicing NVIDIA GPUs in OpenShift</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="time-slicing-nvidia-gpus-in-openshift">
<h1>Time-slicing NVIDIA GPUs in OpenShift<a class="headerlink" href="#time-slicing-nvidia-gpus-in-openshift" title="Permalink to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>The latest generations of NVIDIA GPUs provide a mode of operation called Multi-Instance GPU (MIG).
MIG allows you to partition a GPU into several smaller, predefined instances, each of which looks like a mini-GPU that
provides memory and fault isolation at the hardware layer. Users can share access to a GPU by running their workloads
on one of these predefined instances instead of the full GPU.</p>
<p>This document describes a new mechanism for enabling time-sharing of GPUs in OpenShift. It allows a cluster
administrator to define a set of replicas for a GPU, each of which can be handed out independently to a pod
to run workloads on.</p>
<p>Unlike MIG, there is no memory or fault-isolation between replicas, but for some workloads this is better than not
being able to share at all. Under the hood, Compute Unified Device Architecture (CUDA) time-slicing is used to multiplex workloads from replicas of the
same underlying GPU.</p>
</section>
<section id="configuring-gpus-with-time-slicing">
<h2>Configuring GPUs with time slicing<a class="headerlink" href="#configuring-gpus-with-time-slicing" title="Permalink to this heading"></a></h2>
<p>The following sections show you how to configure NVIDIA Tesla T4 GPUs, as they do not support MIG, but can easily accept multiple small jobs.</p>
<section id="enabling-gpu-feature-discovery">
<h3>Enabling GPU Feature Discovery<a class="headerlink" href="#enabling-gpu-feature-discovery" title="Permalink to this heading"></a></h3>
<p>The feature release on GPU Feature Discovery (GFD) exposes the GPU types as labels and allows users to create node selectors based on these labels to help the scheduler place the pods. By default, when you create a <code class="docutils literal notranslate"><span class="pre">ClusterPolicy</span></code>
custom resource, GFD is enabled. In case, you disabled it, you can re-enable it with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>patch<span class="w"> </span>clusterpolicy<span class="w"> </span>gpu-cluster-policy<span class="w"> </span>-n<span class="w"> </span>nvidia-gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--type<span class="w"> </span>json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--patch<span class="w"> </span><span class="s1">&#39;[{&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/gfd/enable&quot;, &quot;value&quot;: true}]&#39;</span>
</pre></div>
</div>
</section>
<section id="creating-the-slicing-configurations">
<h3>Creating the slicing configurations<a class="headerlink" href="#creating-the-slicing-configurations" title="Permalink to this heading"></a></h3>
<ol class="arabic">
<li><p>Before enabling a time slicing configuration, you need to tell the device plugin what are the possible configurations.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">device-plugin-config</span>
<span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span>
<span class="nt">data</span><span class="p">:</span>
<span class="w">  </span><span class="nt">A100-SXM4-40GB</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|-</span>
<span class="w">    </span><span class="no">version: v1</span>
<span class="w">    </span><span class="no">sharing:</span>
<span class="w">      </span><span class="no">timeSlicing:</span>
<span class="w">        </span><span class="no">resources:</span>
<span class="w">          </span><span class="no">- name: nvidia.com/gpu</span>
<span class="w">            </span><span class="no">replicas: 8</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-1g.5gb</span>
<span class="w">            </span><span class="no">replicas: 1</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-2g.10gb</span>
<span class="w">            </span><span class="no">replicas: 2</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-3g.20gb</span>
<span class="w">            </span><span class="no">replicas: 3</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-7g.40gb</span>
<span class="w">            </span><span class="no">replicas: 7</span>
<span class="w">  </span><span class="nt">A100-SXM4-80GB</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|-</span>
<span class="w">    </span><span class="no">version: v1</span>
<span class="w">    </span><span class="no">sharing:</span>
<span class="w">      </span><span class="no">timeSlicing:</span>
<span class="w">        </span><span class="no">resources:</span>
<span class="w">          </span><span class="no">- name: nvidia.com/gpu</span>
<span class="w">            </span><span class="no">replicas: 8</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-1g.10gb</span>
<span class="w">            </span><span class="no">replicas: 1</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-2g.20gb</span>
<span class="w">            </span><span class="no">replicas: 2</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-3g.40gb</span>
<span class="w">            </span><span class="no">replicas: 3</span>
<span class="w">          </span><span class="no">- name: nvidia.com/mig-7g.80gb</span>
<span class="w">            </span><span class="no">replicas: 7</span>
<span class="w">  </span><span class="nt">Tesla-T4</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|-</span>
<span class="w">    </span><span class="no">version: v1</span>
<span class="w">    </span><span class="no">sharing:</span>
<span class="w">      </span><span class="no">timeSlicing:</span>
<span class="w">        </span><span class="no">resources:</span>
<span class="w">          </span><span class="no">- name: nvidia.com/gpu</span>
<span class="w">            </span><span class="no">replicas: 8</span>
</pre></div>
</div>
</li>
<li><p>Create the ConfigMap:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>device-plugin-config.yaml
</pre></div>
</div>
</li>
<li><p>Tell the GPU Operator which ConfigMap to use for the device plugin configuration. You can simply patch the <code class="docutils literal notranslate"><span class="pre">ClusterPolicy</span></code> custom resource.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>patch<span class="w"> </span>clusterpolicy<span class="w"> </span>gpu-cluster-policy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>nvidia-gpu-operator<span class="w"> </span>--type<span class="w"> </span>merge<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-p<span class="w"> </span><span class="s1">&#39;{&quot;spec&quot;: {&quot;devicePlugin&quot;: {&quot;config&quot;: {&quot;name&quot;: &quot;device-plugin-config&quot;}}}}&#39;</span>
</pre></div>
</div>
</li>
<li><p>Apply the configuration to all the nodes you have with Tesla TA GPUs. GFD, labels the nodes with the GPU product, in this example <code class="docutils literal notranslate"><span class="pre">Tesla-T4</span></code>, so you can use a node selector to label all of the nodes at once.</p>
<p>You can also set <code class="docutils literal notranslate"><span class="pre">devicePlugin.config.default=Tesla-T4</span></code>, which applies the configuration across the cluster by default without requiring node specific labels.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>label<span class="w"> </span>--overwrite<span class="w"> </span>node<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--selector<span class="o">=</span>nvidia.com/gpu.product<span class="o">=</span>Tesla-T4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>nvidia.com/device-plugin.config<span class="o">=</span>Tesla-T4
</pre></div>
</div>
</li>
<li><p>After a few seconds, the configuration is applied and you can verify that GPU resource replicas have been created. The following configuration creates eight replicas for Tesla T4 GPUs, so the <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu</span></code> external resource is set to <code class="docutils literal notranslate"><span class="pre">8</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>--selector<span class="o">=</span>nvidia.com/gpu.product<span class="o">=</span>Tesla-T4-SHARED<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span>jq<span class="w"> </span><span class="s1">&#39;.items[0].status.capacity&#39;</span>
</pre></div>
</div>
<p><strong>Example output</strong></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">  &quot;attachable-volumes-aws-ebs&quot;: &quot;39&quot;,</span>
<span class="go">  &quot;cpu&quot;: &quot;4&quot;,</span>
<span class="go">  &quot;ephemeral-storage&quot;: &quot;125293548Ki&quot;,</span>
<span class="go">  &quot;hugepages-1Gi&quot;: &quot;0&quot;,</span>
<span class="go">  &quot;hugepages-2Mi&quot;: &quot;0&quot;,</span>
<span class="go">  &quot;memory&quot;: &quot;16105592Ki&quot;,</span>
<span class="go">  &quot;nvidia.com/gpu&quot;: &quot;8&quot;,</span>
<span class="go">  &quot;pods&quot;: &quot;250&quot;</span>
<span class="go">}</span>
</pre></div>
</div>
</li>
<li><p>Note that a -SHARED suffix has been added to the <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu.product</span></code> label to reflect that time slicing is enabled. You can disable this in the configuration. For example, the Tesla T4 configuration would look like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">sharing</span><span class="p">:</span>
<span class="w">  </span><span class="nt">timeSlicing</span><span class="p">:</span>
<span class="w">    </span><span class="nt">renameByDefault</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia.com/gpu</span>
<span class="w">        </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
</pre></div>
</div>
</li>
<li><p>Verify that GFD labels have been added to indicate time-sharing.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>--selector<span class="o">=</span>nvidia.com/gpu.product<span class="o">=</span>Tesla-T4-SHARED<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="se">\</span>
<span class="w"> </span><span class="p">|</span><span class="w"> </span>jq<span class="w"> </span><span class="s1">&#39;.items[0].metadata.labels&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>nvidia
</pre></div>
</div>
<p><strong>Example Output</strong></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;510&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;73&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;08&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;7&quot;,</span>
<span class="go">&quot;nvidia.com/device-plugin.config&quot;: &quot;Tesla-T4&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1655482336&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;7&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;5&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.container-toolkit&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.dcgm&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.dcgm-exporter&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.device-plugin&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.driver&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.gpu-feature-discovery&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.node-status-exporter&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.nvsm&quot;: &quot;&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.operator-validator&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;turing&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;g4dn.xlarge&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;16106127360&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.present&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;Tesla-T4-SHARED&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.replicas&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/mig.strategy&quot;: &quot;single&quot;,</span>
</pre></div>
</div>
<p>If you remove the label, the node configuration is reset to its default.</p>
</li>
</ol>
</section>
</section>
<section id="applying-the-configuration-to-a-machineset">
<h2>Applying the configuration to a MachineSet<a class="headerlink" href="#applying-the-configuration-to-a-machineset" title="Permalink to this heading"></a></h2>
<p>With OpenShift, you can leverage the <a class="reference external" href="https://docs.openshift.com/container-platform/4.10/machine_management/index.html">Machine Management</a> feature to dynamically provision nodes on
platforms that support it.</p>
<p>For example, an administrator can create a MachineSet for nodes with Tesla T4 GPUs configured with time-slicing enabled.
This provides a pool of replicas for workloads that don’t require a full T4 GPU.</p>
<p>Consider a MachineSet named <code class="docutils literal notranslate"><span class="pre">worker-gpu-nvidia-t4-us-east-1</span></code>, with
<a class="reference external" href="https://docs.openshift.com/container-platform/4.10/machine_management/applying-autoscaling.html#machine-autoscaler-about_applying-autoscaling">Machine Autoscaler</a> configured.
You want to ensure the new nodes will have time slicing enabled automatically, that is, you want to apply the
label to every new node. This can be done by setting the label in the MachineSet template.</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>patch<span class="w"> </span>machineset<span class="w"> </span>worker-gpu-nvidia-t4-us-east-1a<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>openshift-machine-api<span class="w"> </span>--type<span class="w"> </span>merge<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--patch<span class="w"> </span><span class="s1">&#39;{&quot;spec&quot;: {&quot;template&quot;: {&quot;spec&quot;: {&quot;metadata&quot;: {&quot;labels&quot;: {&quot;nvidia.com/device-plugin.config&quot;: &quot;Tesla-T4&quot;}}}}}}&#39;</span>
</pre></div>
</div>
</div></blockquote>
<p>Now, any new machine created by the Machine Autoscaler for this MachineSet will have the label, and time-slicing enabled.</p>
</section>
<section id="sample-configmap-values">
<h2>Sample ConfigMap values<a class="headerlink" href="#sample-configmap-values" title="Permalink to this heading"></a></h2>
<p>The following table shows sample values for a ConfigMap that contains
multiple <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> files (small, medium, and large).</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 41%" />
<col style="width: 32%" />
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Small</p></th>
<th class="head"><p>Medium</p></th>
<th class="head"><p>Large</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">replicas</span></code></p></td>
<td><p>The number of replicas
that can be specified
for each named resource.</p></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">renameByDefault</span></code></p></td>
<td><p>When <code class="docutils literal notranslate"><span class="pre">false</span></code>, the
<code class="docutils literal notranslate"><span class="pre">SHARED</span></code> suffix is
added to the product
label.</p></td>
<td><p>false</p></td>
<td><p>false</p></td>
<td><p>false</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">failRequestsGreaterThanOne</span></code></p></td>
<td><p>This flag is <code class="docutils literal notranslate"><span class="pre">false</span></code>
for backward
compatibility.</p></td>
<td><p>false</p></td>
<td><p>false</p></td>
<td><p>false</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unlike with standard GPU requests, requesting more than one shared GPU does not guarantee that you will have access to a proportional amount of compute power. It only specifies that you will have access to a GPU that is shared by other clients, each of which has the freedom to run as many processes on the underlying GPU as they want. Internally, the GPU will simply give an equal share of time to all GPU processes across all of the clients. The <code class="docutils literal notranslate"><span class="pre">failRequestsGreaterThanOne</span></code> flag is meant to help users understand this subtlety, by treating a request of 1 as an access request rather than an exclusive resource request. Setting <code class="docutils literal notranslate"><span class="pre">failRequestsGreaterThanOne=true</span></code> is recommended, but it is set to false by default to retain backwards compatibility.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="enable-gpu-op-dashboard.html" class="btn btn-neutral float-left" title="Enable the GPU Operator Dashboard" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nvidia-gpu-operator-openshift-virtualization-vgpu-enablement.html" class="btn btn-neutral float-right" title="NVIDIA GPU Operator with OpenShift Virtualization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-04-10.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>