<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GPU Operator with MIG &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/archive/22.9.0/gpu-operator-mig.html"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../../../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Time-Slicing GPUs in Kubernetes" href="gpu-sharing.html" />
    <link rel="prev" title="Appendix" href="openshift/appendix-ocp.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../../../contents.html">
            <img src="../../../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/contents.html">GPU Operator on OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../appendix.html">Advanced Configurations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../archive.html">Archive</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id1">22.9.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id2">22.9.1</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../archive.html#id3">22.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id4">1.11.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id5">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id6">1.10.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id7">1.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id8">1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id9">1.8</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/install-k8s.html">Install Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/mig-k8s.html">MIG Support in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPUs and Red Hat Device Edge</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../edge/nvidia-gpu-with-device-edge.html">Accelerating workloads with NVIDIA GPUs with Red Hat Device Edge</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mig/mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mig/mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../contents.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../archive.html">Archive</a> &raquo;</li>
      <li>GPU Operator with MIG</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="gpu-operator-with-mig">
<span id="install-gpu-operator-22-9-0-mig"></span><h1>GPU Operator with MIG<a class="headerlink" href="#gpu-operator-with-mig" title="Permalink to this heading"></a></h1>
<p>Multi-Instance GPU (MIG) allows GPUs based on the NVIDIA Ampere architecture
(such as NVIDIA A100) to be securely partitioned into separate GPU Instances for
CUDA applications. Refer to the
<a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">MIG User Guide</a>
for more details on MIG.</p>
<p>This documents provides an overview of how to use the GPU Operator with nodes that support
MIG.</p>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading"></a></h2>
<section id="initial-setup">
<h3>Initial Setup<a class="headerlink" href="#initial-setup" title="Permalink to this heading"></a></h3>
<p>In this example workflow, we start with a MIG strategy of <code class="docutils literal notranslate"><span class="pre">single</span></code>. The <code class="docutils literal notranslate"><span class="pre">mixed</span></code> strategy can also be
specified and used in a similar manner.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In a CSP IaaS environment such as Google Cloud, ensure that the <code class="docutils literal notranslate"><span class="pre">mig-manager</span></code> variable
<code class="docutils literal notranslate"><span class="pre">WITH_REBOOT</span></code> is set to “true”.
Refer to the <a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#enable-mig-mode">note</a>
in the MIG User Guide for more information on the constraints with enabling MIG mode.</p>
</div>
<p>We can use the following option to install the GPU Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--set<span class="w"> </span>mig.strategy<span class="o">=</span>single
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">mig.strategy</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">mixed</span></code> when MIG mode is not enabled on all GPUs on a node.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Starting with v1.9, MIG Manager supports preinstalled drivers. If drivers are preinstalled, use
an additional option during installation <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">driver.enabled=false</span></code>. See <a class="reference internal" href="#mig-with-preinstalled-drivers-22-9-0"><span class="std std-ref">MIG Manager with Preinstalled Drivers</span></a>
for more details.</p>
</div>
<p>At this point, all the pods, including the <code class="docutils literal notranslate"><span class="pre">nvidia-mig-manager</span></code> will be deployed on nodes that have MIG capable GPUs:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-n<span class="w"> </span>gpu-operator
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                                          READY   STATUS      RESTARTS   AGE</span>
<span class="go">gpu-operator-d6ccd4d8d-9cgzr                                  1/1     Running     2          6m58s</span>
<span class="go">gpu-operator-node-feature-discovery-master-867c4f7bfb-4nlq7   1/1     Running     0          6m58s</span>
<span class="go">gpu-operator-node-feature-discovery-worker-6rvr2              1/1     Running     1          6m58s</span>
<span class="go">gpu-feature-discovery-sclxr                                   1/1     Running     0          6m39s</span>
<span class="go">nvidia-container-toolkit-daemonset-tnh82                      1/1     Running     0          6m39s</span>
<span class="go">nvidia-cuda-validator-qt6wq                                   0/1     Completed   0          3m11s</span>
<span class="go">nvidia-dcgm-exporter-dh46q                                    1/1     Running     0          6m39s</span>
<span class="go">nvidia-device-plugin-daemonset-t6qkz                          1/1     Running     0          6m39s</span>
<span class="go">nvidia-device-plugin-validator-sd5f7                          0/1     Completed   0          105s</span>
<span class="go">nvidia-driver-daemonset-f7ktr                                 1/1     Running     0          6m40s</span>
<span class="go">nvidia-mig-manager-gzg8n                                      1/1     Running     0          79s</span>
<span class="go">nvidia-operator-validator-vsccj                               1/1     Running     0          6m39s</span>
</pre></div>
</div>
<p>You can also check the labels applied to the node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>node<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span>jq<span class="w"> </span><span class="s1">&#39;.items[].metadata.labels&#39;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;460&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;73&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;01&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;2&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1621375725&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.container-toolkit&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.dcgm-exporter&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.device-plugin&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.driver&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.gpu-feature-discovery&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.mig-manager&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.operator-validator&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;ampere&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;Google-Compute-Engine&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;40536&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.present&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB&quot;,</span>
<span class="go">&quot;nvidia.com/mig.strategy&quot;: &quot;single&quot;</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The MIG Manager currently requires that all user workloads on the GPUs being configured be stopped.
In some cases, the node may need to be rebooted (esp. in CSP IaaS), so the node may need to be cordoned
before changing the MIG mode or the MIG geometry on the GPUs.</p>
<p>This requirement may be relaxed in future releases.</p>
</div>
</section>
<section id="configuring-mig-profiles">
<h3>Configuring MIG Profiles<a class="headerlink" href="#configuring-mig-profiles" title="Permalink to this heading"></a></h3>
<p>Now, let’s configure the GPU into a supported by setting the <code class="docutils literal notranslate"><span class="pre">mig.config</span></code> label on the
GPU node.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mig-manager</span></code> uses a <cite>ConfigMap</cite> called <code class="docutils literal notranslate"><span class="pre">mig-parted-config</span></code> in the GPU Operator
namespace in the daemonset to include supported MIG profiles. Refer to the <cite>ConfigMap</cite> to use when
changing the label below or modify the <cite>ConfigMap</cite> appropriately for your use-case.</p>
</div>
<p>In this example, we use the <code class="docutils literal notranslate"><span class="pre">1g.5gb</span></code> profile:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>label<span class="w"> </span>nodes<span class="w"> </span><span class="nv">$NODE</span><span class="w"> </span>nvidia.com/mig.config<span class="o">=</span>all-1g.5gb
</pre></div>
</div>
<p>The MIG manager will proceed to apply a <code class="docutils literal notranslate"><span class="pre">mig.config.state</span></code> label to the GPU and then terminate all
the GPU pods in preparation to enable MIG mode and configure the GPU into the desired MIG geometry:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;nvidia.com/mig.config&quot;: &quot;all-1g.5gb&quot;,</span>
<span class="go">&quot;nvidia.com/mig.config.state&quot;: &quot;pending&quot;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kube-system              kube-scheduler-a100-mig-k8s                                   1/1     Running       1          45m</span>
<span class="go">gpu-operator             nvidia-dcgm-exporter-dh46q                                    1/1     Terminating   0          13m</span>
<span class="go">gpu-operator             gpu-feature-discovery-sclxr                                   1/1     Terminating   0          13m</span>
<span class="go">gpu-operator             nvidia-device-plugin-daemonset-t6qkz                          1/1     Terminating   0          13m</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As described above, if the <code class="docutils literal notranslate"><span class="pre">WITH_REBOOT</span></code> option is set then the MIG manager will proceed to reboot the node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;nvidia.com/mig.config&quot;: &quot;all-1g.5gb&quot;,</span>
<span class="go">&quot;nvidia.com/mig.config.state&quot;: &quot;rebooting&quot;</span>
</pre></div>
</div>
</div>
<p>Once the MIG manager has completed applying the configuration changes (including a node reboot if required), the node
labels should appear as shown below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;nvidia.com/cuda.driver.major&quot;: &quot;460&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.minor&quot;: &quot;73&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.driver.rev&quot;: &quot;01&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.major&quot;: &quot;11&quot;,</span>
<span class="go">&quot;nvidia.com/cuda.runtime.minor&quot;: &quot;2&quot;,</span>
<span class="go">&quot;nvidia.com/gfd.timestamp&quot;: &quot;1621442537&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.major&quot;: &quot;8&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.compute.minor&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.count&quot;: &quot;7&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.container-toolkit&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.dcgm-exporter&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.device-plugin&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.driver&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.gpu-feature-discovery&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.mig-manager&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.deploy.operator-validator&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.copy&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.decoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.encoder&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.jpeg&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.engines.ofa&quot;: &quot;0&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.family&quot;: &quot;ampere&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.machine&quot;: &quot;Google-Compute-Engine&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.memory&quot;: &quot;4864&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.multiprocessors&quot;: &quot;14&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.present&quot;: &quot;true&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB-MIG-1g.5gb&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.slices.ci&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.slices.gi&quot;: &quot;1&quot;,</span>
<span class="go">&quot;nvidia.com/mig.config&quot;: &quot;all-1g.5gb&quot;,</span>
<span class="go">&quot;nvidia.com/mig.config.state&quot;: &quot;success&quot;,</span>
<span class="go">&quot;nvidia.com/mig.strategy&quot;: &quot;single&quot;</span>
</pre></div>
</div>
<p>The labels <code class="docutils literal notranslate"><span class="pre">gpu.count</span></code> and <code class="docutils literal notranslate"><span class="pre">gpu.slices</span></code> indicate that the devices are configured. We can also run <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>
in the driver container to verify that the GPU has been configured:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>docker<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>629b93e200d9eea35be35a1b30991d007e48497d52a38e18a472945e44e52a8e<span class="w"> </span>nvidia-smi<span class="w"> </span>-L
<span class="go">GPU 0: A100-SXM4-40GB (UUID: GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f)</span>
<span class="go">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/7/0)</span>
<span class="go">  MIG 1g.5gb Device 1: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/8/0)</span>
<span class="go">  MIG 1g.5gb Device 2: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/9/0)</span>
<span class="go">  MIG 1g.5gb Device 3: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/11/0)</span>
<span class="go">  MIG 1g.5gb Device 4: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/12/0)</span>
<span class="go">  MIG 1g.5gb Device 5: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/13/0)</span>
<span class="go">  MIG 1g.5gb Device 6: (UUID: MIG-GPU-5c89852c-d268-c3f3-1b07-005d5ae1dc3f/14/0)</span>
</pre></div>
</div>
<p>Finally, verify that the GPU Operator pods are in running state:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                                          READY   STATUS      RESTARTS   AGE</span>
<span class="go">gpu-operator-d6ccd4d8d-hhhq4                                  1/1     Running     4          38m</span>
<span class="go">gpu-operator-node-feature-discovery-master-867c4f7bfb-jt95x   1/1     Running     1          38m</span>
<span class="go">gpu-operator-node-feature-discovery-worker-rjpfb              1/1     Running     3          38m</span>
<span class="go">gpu-feature-discovery-drzft                                   1/1     Running     0          97s</span>
<span class="go">nvidia-container-toolkit-daemonset-885b5                      1/1     Running     1          38m</span>
<span class="go">nvidia-cuda-validator-kh4tv                                   0/1     Completed   0          94s</span>
<span class="go">nvidia-dcgm-exporter-6d5kd                                    1/1     Running     0          97s</span>
<span class="go">nvidia-device-plugin-daemonset-kspv5                          1/1     Running     0          97s</span>
<span class="go">nvidia-device-plugin-validator-mpgv9                          0/1     Completed   0          83s</span>
<span class="go">nvidia-driver-daemonset-mgmdb                                 1/1     Running     3          38m</span>
<span class="go">nvidia-mig-manager-svv7b                                      1/1     Running     1          35m</span>
<span class="go">nvidia-operator-validator-w44q8                               1/1     Running     0          97s</span>
</pre></div>
</div>
</section>
<section id="reconfiguring-mig-profiles">
<h3>Reconfiguring MIG Profiles<a class="headerlink" href="#reconfiguring-mig-profiles" title="Permalink to this heading"></a></h3>
<p>The MIG manager supports dynamic reconfiguration of the MIG geometry. In this example, let’s reconfigure the
GPU into a <code class="docutils literal notranslate"><span class="pre">3g.20gb</span></code> profile:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>label<span class="w"> </span>nodes<span class="w"> </span><span class="nv">$NODE</span><span class="w"> </span>nvidia.com/mig.config<span class="o">=</span>all-3g.20gb<span class="w"> </span>--overwrite
</pre></div>
</div>
<p>We can see from the logs of the MIG manager that it has reconfigured the GPU into the new MIG geometry:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Applying the selected MIG config to the node</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Parsing config file...&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Selecting specific MIG config...&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Running apply-start hook&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Checking current MIG mode...&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Walking MigConfig for (devices=all)&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;  GPU 0: 0x20B010DE&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;    Asserting MIG mode: Enabled&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;    MIG capable: true\n&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;    Current MIG mode: Enabled&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Checking current MIG device configuration...&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Walking MigConfig for (devices=all)&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;  GPU 0: 0x20B010DE&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;    Asserting MIG config: map[1g.5gb:7]&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Running pre-apply-config hook&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Applying MIG device configuration...&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Walking MigConfig for (devices=all)&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;  GPU 0: 0x20B010DE&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;    MIG capable: true\n&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;    Updating MIG config: map[1g.5gb:7]&quot;</span>
<span class="go">time=&quot;2021-05-19T16:42:14Z&quot; level=debug msg=&quot;Running apply-exit hook&quot;</span>
<span class="go">MIG configuration applied successfully</span>
<span class="go">Restarting all GPU clients previouly shutdown by reenabling their component-specific nodeSelector labels</span>
<span class="go">node/pramarao-a100-mig-k8s labeled</span>
<span class="go">Changing the &#39;nvidia.com/mig.config.state&#39; node label to &#39;success&#39;</span>
</pre></div>
</div>
<p>And the node labels have been updated appropriately:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;nvidia.com/gpu.product&quot;: &quot;A100-SXM4-40GB-MIG-3g.20gb&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.slices.ci&quot;: &quot;3&quot;,</span>
<span class="go">&quot;nvidia.com/gpu.slices.gi&quot;: &quot;3&quot;,</span>
<span class="go">&quot;nvidia.com/mig.config&quot;: &quot;all-3g.20gb&quot;,</span>
</pre></div>
</div>
<p>We can now proceed to run some sample workloads.</p>
</section>
<section id="running-sample-cuda-workloads">
<span id="mig-examples"></span><h3>Running Sample CUDA Workloads<a class="headerlink" href="#running-sample-cuda-workloads" title="Permalink to this heading"></a></h3>
<section id="cuda-vectoradd">
<h4>CUDA VectorAdd<a class="headerlink" href="#cuda-vectoradd" title="Permalink to this heading"></a></h4>
<p>Let’s run a simple CUDA sample, in this case <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> by requesting a GPU resource as you would
normally do in Kubernetes. In this case, Kubernetes will schedule the pod on a single MIG device and
we use a <code class="docutils literal notranslate"><span class="pre">nodeSelector</span></code> to direct the pod to be scheduled on the node with the MIG devices.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;<span class="w"> </span>EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>kubectl<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>-
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: cuda-vectoradd</span>
<span class="go">spec:</span>
<span class="go">  restartPolicy: OnFailure</span>
<span class="go">  containers:</span>
<span class="go">  - name: vectoradd</span>
<span class="go">    image: nvidia/samples:vectoradd-cuda11.2.1</span>
<span class="go">    resources:</span>
<span class="go">      limits:</span>
<span class="go">        nvidia.com/gpu: 1</span>
<span class="go">  nodeSelector:</span>
<span class="go">    nvidia.com/gpu.product: A100-SXM4-40GB-MIG-1g.5gb</span>
<span class="go">EOF</span>
</pre></div>
</div>
</section>
<section id="concurrent-job-launch">
<h4>Concurrent Job Launch<a class="headerlink" href="#concurrent-job-launch" title="Permalink to this heading"></a></h4>
<p>Now, let’s try a more complex example. In this example, we will use Argo Workflows to launch concurrent
jobs on MIG devices. In this example, the A100 has been configured into 2 MIG devices using the: <code class="docutils literal notranslate"><span class="pre">3g.20gb</span></code> profile.</p>
<p>First, <a class="reference external" href="https://argoproj.github.io/argo-workflows/quick-start/#install-argo-workflows">install</a> the Argo Workflows
components into your Kubernetes cluster.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>ns<span class="w"> </span>argo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="o">&amp;&amp;</span><span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-n<span class="w"> </span>argo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-f<span class="w"> </span>https://raw.githubusercontent.com/argoproj/argo-workflows/stable/manifests/quick-start-postgres.yaml
</pre></div>
</div>
<p>Next, download the latest Argo CLI from the <a class="reference external" href="https://github.com/argoproj/argo-workflows/releases">releases page</a> and
follow the instructions to install the binary.</p>
<p>Now, we will craft an Argo example that launches multiple CUDA containers onto the MIG devices on the GPU.
We will reuse the same <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> example from before. Here is the job description, saved as <code class="docutils literal notranslate"><span class="pre">vector-add.yaml</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">$ cat &lt;&lt; EOF &gt; vector-add.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argoproj.io/v1alpha1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Workflow</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">generateName</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig-example-</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">entrypoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig-result-example</span>
<span class="nt">templates</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig-result-example</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">steps</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">generate</span>
<span class="w">        </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gen-mig-device-list</span>
<span class="w">    </span><span class="c1"># Iterate over the list of numbers generated by the generate step above</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">        </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">        </span><span class="nt">arguments</span><span class="p">:</span>
<span class="w">        </span><span class="nt">parameters</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">            </span><span class="l l-Scalar l-Scalar-Plain">value</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;{{item}}&quot;</span>
<span class="w">        </span><span class="nt">withParam</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;{{steps.generate.outputs.result}}&quot;</span>

<span class="c1"># Generate a list of numbers in JSON format</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gen-mig-device-list</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">script</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python:alpine3.6</span>
<span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">python</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">import json</span>
<span class="w">        </span><span class="no">import sys</span>
<span class="w">        </span><span class="no">json.dump([i for i in range(0, 2)], sys.stdout)</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">retryStrategy</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">limit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="w">    </span><span class="nt">retryPolicy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Always&quot;</span>
<span class="w">    </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">parameters</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">    </span><span class="nt">container</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia/samples:vectoradd-cuda11.2.1</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">        </span><span class="nt">limits</span><span class="p">:</span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">nodeSelector</span><span class="p">:</span>
<span class="w">    </span><span class="nt">nvidia.com/gpu.product</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">A100-SXM4-40GB-MIG-3g.20gb</span>
<span class="l l-Scalar l-Scalar-Plain">EOF</span>
</pre></div>
</div>
<p>Launch the workflow:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>argo<span class="w"> </span>submit<span class="w"> </span>-n<span class="w"> </span>argo<span class="w"> </span>--watch<span class="w"> </span>vector-add.yaml
</pre></div>
</div>
<p>Argo will print out the pods that have been launched:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Name:                argo-mig-example-z6mqd</span>
<span class="go">Namespace:           argo</span>
<span class="go">ServiceAccount:      default</span>
<span class="go">Status:              Succeeded</span>
<span class="go">Conditions:</span>
<span class="go">Completed           True</span>
<span class="go">Created:             Wed Mar 24 14:44:51 -0700 (20 seconds ago)</span>
<span class="go">Started:             Wed Mar 24 14:44:51 -0700 (20 seconds ago)</span>
<span class="go">Finished:            Wed Mar 24 14:45:11 -0700 (now)</span>
<span class="go">Duration:            20 seconds</span>
<span class="go">Progress:            3/3</span>
<span class="go">ResourcesDuration:   9s*(1 cpu),9s*(100Mi memory),1s*(1 nvidia.com/gpu)</span>

<span class="go">STEP                       TEMPLATE                 PODNAME                           DURATION  MESSAGE</span>
<span class="go">✔ argo-mig-example-z6mqd  argo-mig-result-example</span>
<span class="go">├───✔ generate            gen-mig-device-list      argo-mig-example-z6mqd-562792713  8s</span>
<span class="go">└─┬─✔ argo-mig(0:0)(0)    argo-mig                 argo-mig-example-z6mqd-845918106  2s</span>
<span class="go">└─✔ argo-mig(1:1)(0)    argo-mig                 argo-mig-example-z6mqd-870679174  2s</span>
</pre></div>
</div>
<p>If you observe the logs, you can see that the <code class="docutils literal notranslate"><span class="pre">vector-add</span></code> sample has completed on both devices:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>argo<span class="w"> </span>logs<span class="w"> </span>-n<span class="w"> </span>argo<span class="w"> </span>@latest
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">argo-mig-example-z6mqd-562792713: [0, 1]</span>
<span class="go">argo-mig-example-z6mqd-870679174: [Vector addition of 50000 elements]</span>
<span class="go">argo-mig-example-z6mqd-870679174: Copy input data from the host memory to the CUDA device</span>
<span class="go">argo-mig-example-z6mqd-870679174: CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">argo-mig-example-z6mqd-870679174: Copy output data from the CUDA device to the host memory</span>
<span class="go">argo-mig-example-z6mqd-870679174: Test PASSED</span>
<span class="go">argo-mig-example-z6mqd-870679174: Done</span>
<span class="go">argo-mig-example-z6mqd-845918106: [Vector addition of 50000 elements]</span>
<span class="go">argo-mig-example-z6mqd-845918106: Copy input data from the host memory to the CUDA device</span>
<span class="go">argo-mig-example-z6mqd-845918106: CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">argo-mig-example-z6mqd-845918106: Copy output data from the CUDA device to the host memory</span>
<span class="go">argo-mig-example-z6mqd-845918106: Test PASSED</span>
<span class="go">argo-mig-example-z6mqd-845918106: Done</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="mig-manager-with-preinstalled-drivers">
<span id="mig-with-preinstalled-drivers-22-9-0"></span><h2>MIG Manager with Preinstalled Drivers<a class="headerlink" href="#mig-manager-with-preinstalled-drivers" title="Permalink to this heading"></a></h2>
<p>Starting with v1.9, MIG Manager supports preinstalled drivers. Everything detailed in this document
still applies, however there are a few additional details to consider.</p>
<p>During GPU Operator installation, <code class="docutils literal notranslate"><span class="pre">driver.enabled=false</span></code> must be set. The following options
can be used to install the GPU Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--set<span class="w"> </span>driver.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<p>The MIG Manager stops all operator-managed pods that have access to GPUs when applying a MIG reconfiguration.
When drivers are preinstalled, there may be GPU clients on the host that also need to be stopped.</p>
<p>When drivers are preinstalled, the MIG Manager will try stopping and restarting a list of systemd services on the host across
a MIG reconfiguration. The list of services are specified in a <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> to the MIG Manager daemonset. By default,
the GPU Operator creates a <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code>, named <code class="docutils literal notranslate"><span class="pre">default-gpu-clients</span></code>, containing a default list of systemd services.</p>
<p>Below is a sample GPU clients file, <code class="docutils literal notranslate"><span class="pre">clients.yaml</span></code>, used when creating the <code class="docutils literal notranslate"><span class="pre">default-gpu-clients</span></code> <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">systemd-services</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvsm.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvsm-mqtt.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvsm-core.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvsm-api-gateway.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvsm-notifier.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nv_peer_mem.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-dcgm.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dcgm.service</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dcgm-exporter.service</span>
</pre></div>
</div>
<p>In the future, the GPU clients file will be extended to allow specifying more than just systemd services.</p>
<p>The user may modify the default list by directly editing the <code class="docutils literal notranslate"><span class="pre">default-gpu-clients</span></code> <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> post-install. The user can also create their own
custom <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> to be used by the MIG Manager by performing the following steps:</p>
<ul>
<li><p>Create the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>namespace<span class="w"> </span>gpu-operator
</pre></div>
</div>
</li>
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> containing the custom <cite>clients.yaml</cite> file with a list of GPU clients:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>configmap<span class="w"> </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>gpu-clients<span class="w"> </span>--from-file<span class="o">=</span>clients.yaml
</pre></div>
</div>
</li>
<li><p>Install the GPU Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--set<span class="w"> </span>migManager.gpuClientsConfig.name<span class="o">=</span>gpu-clients
<span class="go">    --set driver.enabled=false</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this heading"></a></h2>
<p>The MIG manager is designed as a controller within Kubernetes. It watches for changes to the
<code class="docutils literal notranslate"><span class="pre">nvidia.com/mig.config</span></code> label on the node and then applies the user requested MIG configuration
When the label changes, the MIG Manager first stops all GPU pods (including the <cite>device plugin</cite>, <cite>gfd</cite>
and <cite>dcgm-exporter</cite>). It then stops all host GPU clients listed in the <code class="docutils literal notranslate"><span class="pre">clients.yaml</span></code> ConfigMap
if drivers are preinstalled. Finally, it applies the MIG reconfiguration and restarts the GPU pods (and possibly host GPU clients).
The MIG reconfiguration may also involve a node reboot if required for enabling MIG mode.</p>
<p>The available MIG profiles are specified in a <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> to the MIG manager daemonset. The user may
choose one of these profiles to apply to the <code class="docutils literal notranslate"><span class="pre">mig.config</span></code> label to trigger a reconfiguration of the
MIG geometry.</p>
<p>The MIG manager relies on the <a class="reference external" href="https://github.com/NVIDIA/mig-parted">mig-parted</a> tool to apply the configuration
changes to the GPU, including enabling MIG mode (with a node reboot as required by some scenarios).</p>
<div class="align-default"><img height="360" src="../../../_images/blockdiag-f619becf121b8d2f00cf9dff26b98f186224cdb3.png" width="832" /></div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="openshift/appendix-ocp.html" class="btn btn-neutral float-left" title="Appendix" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="gpu-sharing.html" class="btn btn-neutral float-right" title="Time-Slicing GPUs in Kubernetes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-04-19.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>